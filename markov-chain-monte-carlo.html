<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-12-05 Mon 12:30 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Markov Chain Monte Carlo</title>
<meta name="author" content="Zain Jabbar" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<title></title><link rel="stylesheet" href="/css/main-dark.css" type="text/css"/>
<header><div class="menu"><ul>
<li><a href="/">/</a></li>
<li><a href="/about">/about</a></li>
</ul></div></header>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Markov Chain Monte Carlo</h1>

<div id="outline-container-org43b9a7d" class="outline-2">
<h2 id="org43b9a7d"><span class="section-number-2">1.</span> Problem Statement</h2>
<div class="outline-text-2" id="text-1">
<p>
Given
</p>
<ul class="org-ul">
<li>A target distribution \( P(x) \)</li>
<li>A known function \( f(x) = k P(x) \)</li>
</ul>

<p>
Problem
</p>
<ul class="org-ul">
<li>Is it possible to sample from \( P(x) \)?</li>
</ul>

<p>
Answer
</p>
<ul class="org-ul">
<li>Yes, it is. We will construct a Markov Chain such that \( \pi_x = P(x) \)</li>
</ul>
</div>
</div>


<div id="outline-container-orgddf9f00" class="outline-2">
<h2 id="orgddf9f00"><span class="section-number-2">2.</span> Algorithm</h2>
<div class="outline-text-2" id="text-2">
<p>
Select an initial value for \( x \), call it \( x_0 \).
</p>

<p>
Then for a large number of iterations, \( i = 1, \cdots, m \) repeat the following
</p>

<p>
Draw a candidate from a proposal distribution \( x^* \sim q( x^* \vert x) \)
</p>

<p>
Calculate an acceptance ratio \( \alpha = \frac{f(x^*)}{f(x)} \frac{q(x \vert x^*)}{q(x^* \vert x)} \)
</p>

<p>
Then generate a random number uniformly in \( [0,1] \) call it \( u \).
</p>

<p>
If \( u \leq \alpha \) then accept the new choice of \( x^* \). Meaning \( x_i = x^* \).
</p>

<p>
If \( u > \alpha \) then reject the new choice of \( x^* \). Meaning \( x_i = x \).
</p>
</div>
</div>


<div id="outline-container-org96eabb5" class="outline-2">
<h2 id="org96eabb5"><span class="section-number-2">3.</span> Implementation</h2>
<div class="outline-text-2" id="text-3">
<p>
Tested on \[ f(x) = e^{\frac{-x^2}{2}} \]
</p>


<div id="orgfbec767" class="figure">
<p><img src="./.ob-jupyter/3857c2bdfdf0fd50f137adbd3670559215188637.png" alt="3857c2bdfdf0fd50f137adbd3670559215188637.png" />
</p>
</div>
</div>
</div>


<div id="outline-container-orgaddd57a" class="outline-2">
<h2 id="orgaddd57a"><span class="section-number-2">4.</span> Proof</h2>
<div class="outline-text-2" id="text-4">
</div>
<div id="outline-container-org437e46d" class="outline-3">
<h3 id="org437e46d"><span class="section-number-3">4.1.</span> Aperiodic and Irreducible</h3>
<div class="outline-text-3" id="text-4-1">
<div class="THEOREM" id="orge954b92">
<p>
An irreducible, aperiodic Markov chain has a unique stationary distribution if it exists.
</p>

</div>

<div class="PROOF" id="orgd9e2b5a">
<p>
In the book, Theorem 4.3.3.
</p>

</div>
</div>
</div>


<div id="outline-container-org2c5ea94" class="outline-3">
<h3 id="org2c5ea94"><span class="section-number-3">4.2.</span> Detailed Balance</h3>
<div class="outline-text-3" id="text-4-2">
<div class="DEFINITION" id="orgcd753a9">
<p>
Suppose we have a Markov Chain with:
</p>
<ul class="org-ul">
<li>Transition probabilities \( P_{ij} \)</li>
<li>Distribution of states \( \pi_i \)</li>
</ul>

<p>
Such that,
</p>

<p>
\( \pi_{i} P_{ij} = \pi_{j} P_{ji} \)
</p>

<p>
Then \( \pi_i \) satisfies detailed balance with respect to the Markov Chain.
</p>

</div>

<div class="THEOREM" id="orgb087d23">
<p>
Suppose we have a Markov Chain with:
</p>
<ul class="org-ul">
<li>Transition probabilities \( P_{ij} \)</li>
<li>Distribution of states \( \pi_i \) that satisfies detailed balance.</li>
</ul>

<p>
Then \( \pi \) is a stationary distribution of the Markov Chain.
</p>

</div>

<div class="PROOF" id="org51b64a9">
\begin{align*}
\forall j, \sum_{i} \pi_i P_{ij} = \sum_{i} \pi_j P_{ji} = \pi_j \sum_{i} P_{ji} = \pi_{j}
\end{align*}

</div>
</div>
</div>


<div id="outline-container-org77c837d" class="outline-3">
<h3 id="org77c837d"><span class="section-number-3">4.3.</span> Proof</h3>
<div class="outline-text-3" id="text-4-3">
<div class="PROOF" id="org0e65763">
<p>
Let
</p>
<ul class="org-ul">
<li>\( q(x^* \vert x) \) have nonzero density for every point in the target distribution</li>
<li>\( \alpha(x,x^*) = \min \left( 1, \frac{P(x^*) q(x \vert x^*)}{P(x) q(x^* \vert x)} \right) = \min \left( 1, \frac{f(x^*) q(x \vert x^*)}{f(x) q(x^* \vert x)} \right) \)</li>
<li>\( P_{x x^*} = P(X_n = x^* \vert X_{n-1} = x) = \begin{cases} q(x^* \vert x) \alpha(x,x^*) & x^* \neq x \\ q(x \vert x) + \sum_{x^* \neq x} q(x, x^*)(1 - \alpha(x,x^*)) & x^* = x \end{cases} \)</li>
</ul>

<p>
Note that \( \alpha(x,x^*) =  \) coordinatewise reciprocols of \( \alpha(x^*,x) \). so WLOG assume \( a(x^*,x) = 1, a(x,x^*) = \frac{P(x^*) q(x \vert x^*)}{P(x) q(x^* \vert x)} \)
Also note that detailed balence is statisfied when the two states are the same. Assume \( x^* \neq x \).
</p>

\begin{align}
&&f(x^*) q(x^* \vert x) &= f(x^*) q(x^* \vert x) \\
&\implies &\frac{f(x) q(x \vert x^*)}{f(x) q(x \vert x^*)}  f(x^*) q(x^* \vert x) &= f(x^*) q(x^* \vert x) \\
&\implies &f(x) q(x \vert x^*) \alpha(x,x^*) &= f(x^*) q(x^* \vert x) \alpha(x^*, x) \\
&\implies &p(x) q(x \vert x^*) \alpha(x,x^*) &= p(x^*) q(x^* \vert x) \alpha(x^*, x) \\
&\implies &p(x) P_{x,x^*} &= p(x^*) P_{x^*x}
\end{align}

<p>
Thus \( p(x) \) satisfies detailed balance and is stationary for the chain with transition probabilities \( P \) described above.
</p>

<p>
Uniqueness is determined by the choice of \( q \). Because \( q \) has nonzero density for every state, the chain can transition to any state from any other state, hence the chain is irreducible and aperiodic.
</p>

<p>
Thus, the Markov chain will converge to its unique stationary distribution \( \pi(i) \) as \( t \to \infty \) which is equal to \( p(i) \).
</p>

</div>
</div>
</div>
</div>


<div id="outline-container-org729c833" class="outline-2">
<h2 id="org729c833"><span class="section-number-2">5.</span> Applications</h2>
<div class="outline-text-2" id="text-5">
<p>
Monte Carlo Markov Chain has many applications.
</p>
</div>

<div id="outline-container-orge4e960f" class="outline-3">
<h3 id="orge4e960f"><span class="section-number-3">5.1.</span> Bayesian Inference</h3>
<div class="outline-text-3" id="text-5-1">
<p>
Suppose we would like to know how likely parameters \( \theta \) are in a model to data \( X \).
</p>

<p>
That is, suppose we are given data from some experiment, and the histogram looks like a Normal distribution. 
</p>


<div id="org150019c" class="figure">
<p><img src="./.ob-jupyter/389964c27b624a440918d397762a0b1184bd229d.png" alt="389964c27b624a440918d397762a0b1184bd229d.png" />
</p>
</div>

<p>
Then we would like to model the data using the Normal distribution.
</p>

<p>
\[ \frac{1}{\sqrt{2 \pi \sigma^2}} e^{\frac{-1}{2} \left( \frac{x - \mu}{\sigma} \right)^2} \]
</p>


<p>
We would then like to ask, given the data, \( X \), what are the odds that the true mean and variance of the population is \( \mu = 0, \sigma^2 = 1 \). Symbolically,
</p>

<p>
\[ P(\mu = 0, \sigma^2 = 1 \vert X) = ? \]
</p>

<p>
We may compute this using Bayes' Theorem.
</p>

<p>
\[ P(\mu = 0, \sigma^2 = 1 \vert X) = \frac{P(X \vert \mu = 0, \sigma^2 = 1) P(\mu = 0, \sigma^2 = 1)}{P(X)} \]
</p>

<p>
The denominator is called the evidence, and is calculated using the law of total probability.
</p>

<p>
\[ P(X) = \int_{\theta \in \Theta} P(X \vert \theta) P(\theta) d \theta \]
</p>

<p>
This integral in general is very tough to compute. We may skip the process by noticing that
</p>

<p>
\[ P(\mu = 0, \sigma^2 = 1 \vert X) \propto P(X \vert \mu = 0, \sigma^2 = 1) P(\mu = 0, \sigma^2 = 1) \]
</p>

<p>
Hence we may calculate the probability density of \( P(\mu = 0, \sigma^2 = 1 \vert X) \) by running MCMC on \( f(\mu, \theta) = P(X \vert \mu, \sigma^2) P(\mu, \sigma^2) \).
</p>

<p>
This fundementally changed the course of statistics by allowing Bayesian Inference to be computationally tractible.
</p>

<p>
This approach allows for parameter estimation in models. My time with 'Ike Wai was about implementing an MCMC program in Matlab using multiple parallel chains to test convergence on some groundwater PDE's.
</p>

<p>
<a href="https://github.com/Zaijab/DREAM">https://github.com/Zaijab/DREAM</a>
</p>

<p>
<a href="https://www.frontiersin.org/articles/10.3389/fams.2019.00055/full">https://www.frontiersin.org/articles/10.3389/fams.2019.00055/full</a>
</p>
</div>
</div>


<div id="outline-container-org368f30b" class="outline-3">
<h3 id="org368f30b"><span class="section-number-3">5.2.</span> Numerical Integration - How to calculate expectation and variance using Markov Chains</h3>
<div class="outline-text-3" id="text-5-2">
</div>
<div id="outline-container-org31abc8e" class="outline-4">
<h4 id="org31abc8e"><span class="section-number-4">5.2.1.</span> Monte Carlo Integration</h4>
<div class="outline-text-4" id="text-5-2-1">
<p>
One way to calculate an integral
</p>

<p>
\[ \int_{a}^{b} f(x) dx \]
</p>

<p>
Is to use samples randomly distributed over the interval \( [a,b] \).
</p>

<p>
That is, suppose we have a sequence of \( X_i \in [a,b] \) sampled iid uniformly.
</p>

<p>
Then,
</p>

\begin{align*}
\mathbb{E} \left[\frac{(b - a)}{n} \sum_{i = 0}^{n - 1} f(X_i) \right]
&= \frac{(b - a)}{n} \sum_{i = 0}^{n - 1} \mathbb{E} \left[ f(X_i) \right] \\
&= \frac{(b - a)}{n} \sum_{i = 0}^{n - 1} \int_{a}^{b} f(X_i) dP \\
&= \frac{(b - a)}{n} \sum_{i = 0}^{n - 1} \int_{a}^{b} f(x) \frac{1}{(b - a)} dx \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{a}^{b} f(x) dx \\
&= \int_{a}^{b} f(x) dx
\end{align*}

<p>
This works for numerical integration. Let us calculate \( \pi \) by numerically integrating over the semicircle.
</p>

<pre class="example">
3.139974059799566
</pre>


<p>
Note the bounds of integration, we only proved this for a bounded domain of integration. What happens when the domain of integration is unbounded?
</p>
</div>
</div>


<div id="outline-container-org120ec4f" class="outline-4">
<h4 id="org120ec4f"><span class="section-number-4">5.2.2.</span> MCMC Integration</h4>
<div class="outline-text-4" id="text-5-2-2">
<p>
Suppose we had an absolutely integrable function \( f \in L^1(\mathbb{R}) \).
</p>

<p>
We may integrate the function using the previous Monte Carlo method by approximating.
</p>

<p>
\[ \int_{-\infty}^{\infty} f(x) dx = \lim_{a \to \infty} \int_{-a}^{a} f(x) dx \]
</p>

<p>
However this does not work well computationally. The reason being, \( \lim_{x \to \infty} f(x) \to 0 \) 
</p>

<p>
This means that as the bounds of integration grows, the many new points will be very close to \( 0 \) and will not contribute much to the integral. So many points sampled by the computer will be for not much benefit. We would like a selection of points sampled "smartly". Rather than sample uniformly, we may sample according to the PDF of the \( X_i \). We can approximate the PDF using MCMC.
</p>

\begin{align*}
\mathbb{E} \left[\frac{1}{n} \sum_{i = 0}^{n - 1} \frac{f(X_i)}{p(X_i)} \right]
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \mathbb{E} \left[ \frac{f(X_i)}{p(X_i)} \right] \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{-\infty}^{\infty} \frac{f(X_i)}{p(X_i)} dP \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{-\infty}^{\infty} \frac{f(x)}{p(x)} p(x) dx \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{-\infty}^{\infty} f(x) dx \\
&= \int_{-\infty}^{\infty} f(x) dx
\end{align*}

<p>
Let us apply MCMC to numerically verify
</p>

<p>
\[ \int_{-\infty}^{\infty} \frac{1}{x^2 + 1} dx = \pi \]
</p>

<pre class="example">
3.3693992934018846
</pre>


<div id="org2eb82ab" class="figure">
<p><img src="./.ob-jupyter/63dae92a8dad1f14a241710f48f825fb99f3032e.png" alt="63dae92a8dad1f14a241710f48f825fb99f3032e.png" />
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-org6c3e9e5" class="outline-3">
<h3 id="org6c3e9e5"><span class="section-number-3">5.3.</span> Sampling Points on a Cow</h3>
<div class="outline-text-3" id="text-5-3">
<p>
Here is a non-standard use of MCMC to sample points on a 3D model of a Cow.
Define a function
</p>

<p>
\[ e^{-100 ||d||} \]
</p>

<p>
Where \( ||d|| \) is the shortest distance from a point in \( \mathbb{R}^3 \) to the cow. Such a \( ||d|| \) can be calculated using high speed (GPU-Optimized) tools for video games like ray tracing. Using MCMC allows us to sample points on the cow.
</p>

<p>
<a href="flashcard_media/Using the Random Walk Metropolis algorithm to sample from a cow surface distribution [0MzH69hFdkE].webm">Cow Video</a>
</p>
</div>
</div>


<div id="outline-container-org97ac23e" class="outline-3">
<h3 id="org97ac23e"><span class="section-number-3">5.4.</span> Speeding Up Theorem Proving</h3>
<div class="outline-text-3" id="text-5-4">
<p>
Here is a paper <a href="https://link.springer.com/chapter/10.1007/978-3-031-10769-6_33">Bayesian Ranking for Strategy Scheduling in Automated Theorem Provers</a>.
</p>
</div>
</div>
</div>


<div id="outline-container-orgda933a8" class="outline-2">
<h2 id="orgda933a8"><span class="section-number-2">6.</span> References</h2>
<div class="outline-text-2" id="text-6">
<p>
Ross, S. M. (1996). Stochastic processes. India: Wiley.
</p>

<p>
Matsuura, S., Hanada, M. (2022). MCMC from Scratch: A Practical Introduction to Markov Chain Monte Carlo. Singapore: Springer Nature Singapore.
</p>

<p>
Mangla, C., Holden, S.B., Paulson, L.C. (2022). Bayesian Ranking for Strategy Scheduling in Automated Theorem Provers. In: Blanchette, J., Kovács, L., Pattinson, D. (eds) Automated Reasoning. IJCAR 2022. Lecture Notes in Computer Science(), vol 13385. Springer, Cham. <a href="https://doi.org/10.1007/978-3-031-10769-6_33">https://doi.org/10.1007/978-3-031-10769-6_33</a>
</p>

<p>
SpartacanUsuals, director. YouTube, YouTube, 15 May 2018, <a href="https://www.youtube.com/watch?v=0MzH69hFdkE">https://www.youtube.com/watch?v=0MzH69hFdkE</a>. Accessed 30 Nov. 2022.
</p>

<p>
Valderrama-Bahamóndez GI and Fröhlich H (2019) MCMC Techniques for Parameter Estimation of ODE Based Models in Systems Biology. Front. Appl. Math. Stat. 5:55. doi: 10.3389/fams.2019.00055
</p>
</div>
</div>
</div>
</body>
</html>

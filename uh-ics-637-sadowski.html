<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-10-03 Thu 14:12 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>UH ICS 637 Sadowski</title>
<meta name="author" content="Zain Jabbar" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>

          <link rel="stylesheet" href="static/css/site.css" type="text/css"/>
          <header><div class="menu"><ul>
          <li><a href="/">/</a></li>
          <li><a href="/about">/about</a></li>
          <li><a href="/posts">/posts</a></li></ul></div></header>
          <script src="static/js/nastaliq.js"></script>
          <script src="static/js/stacking.js"></script>
          <link href='https://unpkg.com/tippy.js@6.2.3/themes/light.css' rel='stylesheet'>
          <script src="https://unpkg.com/@popperjs/core@2"></script>
          <script src="https://unpkg.com/tippy.js@6"></script>
          <script>
          document.addEventListener('DOMContentLoaded', function() {
            let page = document.querySelector('.page');
            if (page) {
              initializePreviews(page);
            }
          });
          </script>
<script>MathJax = { loader: { load: ['[custom]/xypic.js'], paths: {custom: 'https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/'} }, tex: { packages: {'[+]': ['xypic']}, macros: { R: "{\\bf R}" } } };</script><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js"></script>
<div class="grid-container"><div class="ds-grid"><div class="page">
<script>MathJax = { loader: { load: ['[custom]/xypic.js'], paths: {custom: 'https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/'} }, tex: { packages: {'[+]': ['xypic']}, macros: { R: "{\\bf R}" } } };</script><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">UH ICS 637 Sadowski</h1>
<p>
Class at <a href="university-of-hawaii-at-manoa.html#ID-2728f603-9489-4920-bdf6-e56ea4c5c6de">University of Hawaii at Manoa</a>.
</p>
<div id="outline-container-org62e2b2f" class="outline-2">
<h2 id="org62e2b2f"><span class="section-number-2">1.</span> ICS 637 Homework 1</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org3f113a1" class="outline-3">
<h3 id="org3f113a1"><span class="section-number-3">1.1.</span> Problem 13.1 Backpropagation for a MLP</h3>
<div class="outline-text-3" id="text-1-1">
<p>
Consider the following classification MLP with one hidden layer:
</p>

\begin{align}
\mathbf{x} &= \text{input} \in \mathbb{R}^D \\
\mathbf{z} &= \mathbf{Wx + b_1} \in \mathbb{R}^K \\
\mathbf{h} &= \operatorname{ReLU}(\mathbf{z}) \in \mathbb{R}^K \\
\mathbf{a} &= \mathbf{Vh + b_2} \in \mathbb{R}^C \\
\mathcal{L} &= \operatorname{CrossEntropyWithLogits}(\mathbf{y}, \mathbf{a}) \in \mathbb{R} \\
\end{align}
<p>
We would like to calculate the following quantities. Each under its own section.
</p>
</div>
</div>
<div id="outline-container-orgcd67d0f" class="outline-3">
<h3 id="orgcd67d0f"><span class="section-number-3">1.2.</span> \( \mathbf{u}_1 \)</h3>
<div class="outline-text-3" id="text-1-2">
\begin{align}
\mathbf{u}_1
&= \nabla_{\mathbf{z}} \mathcal{L} \tag{Given} \\
&= \left(\frac{ \partial \mathcal{L}}{\partial \mathbf{z}} \right)^T \tag{Definition} \\
&= \left(
\frac{ \partial \mathcal{L}}{\partial \mathbf{a}}
\frac{ \partial \mathbf{a}}{\partial \mathbf{h}}
\frac{ \partial \mathbf{h}}{\partial \mathbf{z}} \right)^T \tag{Chain Rule} \\
&= \left(\mathbf{u}_2^T \mathbf{V} \odot H(\mathbf{z}) \right)^T \tag{Evaluate Jacobians} \\
&= \mathbf{V}^T \mathbf{u}_2 \odot H(\mathbf{z}) \tag{Simplify Transpose}
\end{align}
</div>
</div>
<div id="outline-container-org1b783a1" class="outline-3">
<h3 id="org1b783a1"><span class="section-number-3">1.3.</span> \( \mathbf{u}_2 \)</h3>
<div class="outline-text-3" id="text-1-3">
\begin{align}
\mathbf{u}_2
&= \nabla_{\mathbf{a}} \mathcal{L} \tag{Given} \\
&=  \left( \frac{ \partial \mathcal{L}}{\partial \mathbf{a}} \right)^T \tag{Definition} \\
&=  (\mathbf{p} - \mathbf{y}) \tag{In text, Eq. 13.39}
\end{align}
</div>
</div>
<div id="outline-container-orgffe4682" class="outline-3">
<h3 id="orgffe4682"><span class="section-number-3">1.4.</span> \( \nabla_{\mathbf{V}} \mathcal{L} \)</h3>
<div class="outline-text-3" id="text-1-4">
\begin{align}
\nabla_{\mathbf{V}} \mathcal{L}
&= \left[ \frac{\partial \mathcal{L}}{\partial \mathbf{V}} \right]_{1,:} \tag{Given} \\
&= \left[ \frac{\partial \mathcal{L}}{\partial \mathbf{a}} \frac{\partial \mathbf{a}}{\partial \mathbf{V}} \right]_{1,:} \tag{Chain Rule} \\
&= \left[ \mathbf{u}_2^T \frac{\partial \mathbf{a}}{\partial \mathbf{V}} \right]_{1,:} \tag{Eq. $13.39$} \\
&= \mathbf{u}_2 \mathbf{h}^T \tag{Eq. $13.55$}
\end{align}
</div>
</div>
<div id="outline-container-orgf1c0359" class="outline-3">
<h3 id="orgf1c0359"><span class="section-number-3">1.5.</span> \( \nabla_{\mathbf{b_2}} \mathcal{L} \)</h3>
<div class="outline-text-3" id="text-1-5">
\begin{align}
\nabla_{\mathbf{b_2}} \mathcal{L}
&= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{b_2}} \right)^T \tag{Given} \\
&= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{a}} \frac{\partial \mathbf{a}}{\partial \mathbf{b_2}} \right)^T \tag{Chain Rule} \\
&= \left( \mathbf{u}_2^T \mathbf{I} \right)^T \tag{Evaluate Jacobians} \\
&=  \mathbf{u}_2 \tag{Matrix Simplifications}
\end{align}
</div>
</div>
<div id="outline-container-org7fb5467" class="outline-3">
<h3 id="org7fb5467"><span class="section-number-3">1.6.</span> \( \nabla_{\mathbf{W}} \mathcal{L} \)</h3>
<div class="outline-text-3" id="text-1-6">
\begin{align}
\nabla_{\mathbf{W}} \mathcal{L}
&= \left[ \frac{\partial \mathcal{L}}{\partial \mathbf{W}} \right]_{1,:} \tag{Given} \\
&= \left[ \frac{\partial \mathcal{L}}{\partial \mathbf{z}}
          \frac{\partial \mathbf{z}}{\partial \mathbf{W}} \right]_{1,:} \tag{Chain Rule} \\
&= \left[ \mathbf{u}_1^T \frac{\partial \mathbf{z}}{\partial \mathbf{W}} \right]_{1,:} \tag{Eq. 13.122} \\
&= \mathbf{u}_1 \mathbf{x}^T  \tag{Eq. 13.55}
\end{align}
</div>
</div>
<div id="outline-container-org8143599" class="outline-3">
<h3 id="org8143599"><span class="section-number-3">1.7.</span> \( \nabla_{\mathbf{b}_1} \mathcal{L} \)</h3>
<div class="outline-text-3" id="text-1-7">
\begin{align}
\nabla_{\mathbf{b}_1} \mathcal{L}
&= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{b}_1} \right)^T \tag{Given} \\
&= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{z}}
          \frac{\partial \mathbf{z}}{\partial \mathbf{b}_1} \right)^T \tag{Chain Rule} \\
&= \left( \mathbf{u}_1^T  \mathbf{I} \right)^T \tag{Eq. 13.122} \\
&= \mathbf{u}_1  \tag{Matrix Simplification}
\end{align}
</div>
</div>
<div id="outline-container-orgc31fc4b" class="outline-3">
<h3 id="orgc31fc4b"><span class="section-number-3">1.8.</span> \( \nabla_{\mathbf{x}} \mathcal{L} \)</h3>
<div class="outline-text-3" id="text-1-8">
\begin{align}
\nabla_{\mathbf{b}_1} \mathcal{L}
&= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{x}} \right)^T \tag{Given} \\
&= \left( \frac{\partial \mathcal{L}}{\partial \mathbf{z}}
          \frac{\partial \mathbf{z}}{\partial \mathbf{x}} \right)^T \tag{Chain Rule} \\
&= \left( \mathbf{u}_1^T  W \right)^T \tag{Eq. 13.122} \\
&= W^T \mathbf{u}_1  \tag{Matrix Simplification}
\end{align}
</div>
</div>
</div>
<div id="outline-container-org2494509" class="outline-2">
<h2 id="org2494509"><span class="section-number-2">2.</span> Final Project Paper</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orga1658d9" class="outline-3">
<h3 id="orga1658d9"><span class="section-number-3">2.1.</span> Problem Introduction</h3>
<div class="outline-text-3" id="text-2-1">
<p>
In 2015, house bill 1509 was signed into law establishing a collective goal for The University of Hawaii "to become net-zero with respect to energy use, producing as much (renewable) energy as the system consumes across all campuses by January 1, 2035.". The University's plans are manifold, but fall into three main areas: energy management, efficiency and generation, and social initiatives. The scope of this paper is within the energy management side, to "continue to improve metering and submetering to provide detailed energy tracking.".
</p>

<p>
Tracking and predicting power consumption has many uses for the University. Firstly, we must measure what we aim to reduce. The power demanded on a given day is a random vector. Just because the power demanded was high on a day does not necessarily entail that Manoa is on the wrong track for meeting net zero goals. Deviation from a believable prediction is more indicative of an anomaly than an absolute amount. Second, the University of Hawaii is billed based on the amount of energy used during a month and importantly also based on the largest peak demand in a year. If we have an accurate method of predicting the power demand, we might have a better time predicting when the peak demand will occur and will have a chance at mitigating the peak. 
</p>

<p>
The goal of this paper is to propose a model which may forecast future power usage given an electrical meter time series. The algorithm proposed is a deep LSTM RNN architecture using weather and calendar data.
</p>
</div>
</div>
<div id="outline-container-org29857bf" class="outline-3">
<h3 id="org29857bf"><span class="section-number-3">2.2.</span> Related Work</h3>
<div class="outline-text-3" id="text-2-2">
<p>
The power a building demands is based on the number of electrical devices and how much power they draw. For most devices, we do not expect user to constantly turn the devices on and off. We also expect that the devices tend to be activated in response to an external factor rather than being completely scheduled according to the time of day. This makes a model which only takes in the time of day and returns a point prediction of the amount of power drawn hard to justify. 
</p>

<p>
Instead, when one turns on their computer, laundry machine, or ventilation system, we expect the amount of power drawn to be similar to the amount of power drawn in the past point in time by continuity. Much of the research into power prediction factors this inductive bias into their model.
</p>

<p>
Sachin et al. analyzes short and long term energy consumption time series data using three models, ARIMA, RNN, and LSTM. All of these models use a recursive approach using historical data to predict the next output, then by chaining the outputs we can forecast longer timescales. ARIMA is different from RNN and LSTM models as it does not require auto differentiation. ARIMA is a more interpretable model and is simpler which makes it a common baseline to test other models versus. Notably, Sachin et. al. finds that ARIMA works better for short scale forecasts than RNN and LSTM models, but the opposite is true on longer scale forecasting problems.
</p>
</div>
</div>
<div id="outline-container-org9552762" class="outline-3">
<h3 id="org9552762"><span class="section-number-3">2.3.</span> Dataset</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Prior to 2019, all electrical meters were read manually by maintenance once a month whenever the team had the time to visit the meter. By funding from Elemental Excelerator, the University of Hawaii was able to hire Blue Pillar to install a digital metering system. For a while, data was requested from Blue Pillar and manually sent to ERDL via DropBox. Starting this year January 21 was when I was able to get access to the API and automatically download data for ERDL. 
</p>

<p>
The data from Blue Pillar can be separated into data tables for a given unit and metadata tables. Here is one row from the historical output by BluePillar:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left"><code>SiteId</code></td>
<td class="org-left"><code>17abfe2a-3ae5-471b-965c-3e88e42f28d8</code></td>
</tr>

<tr>
<td class="org-left"><code>SiteName</code></td>
<td class="org-left"><code>UNIVERSITY OF HAWAII AT MANOA</code></td>
</tr>

<tr>
<td class="org-left"><code>TagId</code></td>
<td class="org-left"><code>99784f9d-b44d-413a-90a4-0cee5dcdb33c</code></td>
</tr>

<tr>
<td class="org-left"><code>SiteDateTime</code></td>
<td class="org-left"><code>2022-12-19 01:30:00</code></td>
</tr>

<tr>
<td class="org-left"><code>DateTimeUtc</code></td>
<td class="org-left"><code>2022-12-19 11:30:00</code></td>
</tr>

<tr>
<td class="org-left"><code>Mean</code></td>
<td class="org-left"><code>157798.52920000005</code></td>
</tr>

<tr>
<td class="org-left"><code>Min</code></td>
<td class="org-left"><code>157798.32</code></td>
</tr>

<tr>
<td class="org-left"><code>Max</code></td>
<td class="org-left"><code>157798.74</code></td>
</tr>

<tr>
<td class="org-left"><code>Median</code></td>
<td class="org-left"><code>0</code></td>
</tr>

<tr>
<td class="org-left"><code>Sample</code></td>
<td class="org-left"><code>157798</code></td>
</tr>

<tr>
<td class="org-left"><code>StDev</code></td>
<td class="org-left"><code>0.010360180170754884</code></td>
</tr>

<tr>
<td class="org-left"><code>SampleSize</code></td>
<td class="org-left"><code>900</code></td>
</tr>

<tr>
<td class="org-left"><code>ActualSampleSize</code></td>
<td class="org-left"><code>432</code></td>
</tr>

<tr>
<td class="org-left"><code>Quality</code></td>
<td class="org-left"><code>t</code></td>
</tr>

<tr>
<td class="org-left"><code>MinTsUtc</code></td>
<td class="org-left"><code>2023-01-10 11:26:47.41</code></td>
</tr>

<tr>
<td class="org-left"><code>MaxTsUtc</code></td>
<td class="org-left"><code>2023-01-10 11:26:47.41</code></td>
</tr>

<tr>
<td class="org-left"><code>SampleTsUtc</code></td>
<td class="org-left"><code>2023-01-10 11:26:47.41</code></td>
</tr>
</tbody>
</table>

<p>
We are also able to pull a metadata table of all possible historical data selections. Here is one example row.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left"><code>Id</code></td>
<td class="org-left"><code>009adfb4-d0d4-478d-b8ff-d9d3f2a97427</code></td>
</tr>

<tr>
<td class="org-left"><code>Name</code></td>
<td class="org-left"><code>kW</code></td>
</tr>

<tr>
<td class="org-left"><code>Entity</code></td>
<td class="org-left"><code>HALE_HALAWAI_MAIN_MTR</code></td>
</tr>

<tr>
<td class="org-left"><code>SiteName</code></td>
<td class="org-left"><code>UNIVERSITY OF HAWAII AT MANOA</code></td>
</tr>

<tr>
<td class="org-left"><code>SiteId</code></td>
<td class="org-left"><code>17ABFE2A-3AE5-471B-965C-3E88E42F28D8</code></td>
</tr>

<tr>
<td class="org-left"><code>Building</code></td>
<td class="org-left"><code>HALE HALAWAI</code></td>
</tr>

<tr>
<td class="org-left"><code>Floor</code></td>
<td class="org-left"><code>BASEMENT</code></td>
</tr>

<tr>
<td class="org-left"><code>Room</code></td>
<td class="org-left"><code>ELECTRICAL ROOM</code></td>
</tr>

<tr>
<td class="org-left"><code>DataType</code></td>
<td class="org-left"><code>analog</code></td>
</tr>

<tr>
<td class="org-left"><code>Filter_Id</code></td>
<td class="org-left"><code>d9f52bf2-dcc7-4bbd-a981-6596556f848d</code></td>
</tr>

<tr>
<td class="org-left"><code>Filter_Name</code></td>
<td class="org-left"><code>AllkW</code></td>
</tr>

<tr>
<td class="org-left"><code>building_id</code></td>
<td class="org-left"><code>1260037276</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-orgfca633c" class="outline-3">
<h3 id="orgfca633c"><span class="section-number-3">2.4.</span> Extra Features</h3>
<div class="outline-text-3" id="text-2-4">
<p>
The data in the previous section is the one we would like to forecast. However, because we are given the date and time in which a reading occurs, we may use extra data to aid in our forecasting. We will include calendar metadata, such as what kind of day (holiday, school day, weekend) for a timestamp. We also have weather readings from the FROG buildings on campus. These include the temperature, global horizontal irradiance, and humidity.  
</p>
</div>
</div>
<div id="outline-container-org70805b6" class="outline-3">
<h3 id="org70805b6"><span class="section-number-3">2.5.</span> Features and Preprocessing</h3>
<div class="outline-text-3" id="text-2-5">
</div>
<div id="outline-container-org4d86f01" class="outline-4">
<h4 id="org4d86f01"><span class="section-number-4">2.5.1.</span> Original Shape Structure</h4>
<div class="outline-text-4" id="text-2-5-1">
<p>
After removing much of the metadata related to the location of POST (<code>SiteID</code>, <code>FilterId</code>, etc) we are given a time series of the amount of demand (in kilowatt) at a time and date (down sampled to be in hourly resolution).
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Datetime</th>
<th scope="col" class="org-left">KW</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><code>2022-08-01 00:00:00</code></td>
<td class="org-left"><code>1400.001</code></td>
</tr>
</tbody>
</table>

<p>
The rows are taken only on days in which all the meters give full data. Sometimes one or more meters associated with POST will disconnect from the network and will flatline. This will not result in an accurate reading for the proper level of demand for POST. We choose to omit the results here.
</p>
</div>
</div>
<div id="outline-container-org213049a" class="outline-4">
<h4 id="org213049a"><span class="section-number-4">2.5.2.</span> Date and Time Engineering</h4>
<div class="outline-text-4" id="text-2-5-2">
<p>
Date and time data are stored as <code>pd.Datetime</code> objects in Python and are not easily comparable in tensor form. One way to engineer dates and times is to assign a number like the Linux Epoch, but that will not convey our domain knowledge of the seasonality of yearly, monthly, and weekly trends. By the law of trichotomy, a single real number cannot be used to represent a cyclic pattern. Hence, given a <code>pd.Datetime</code> object, we represent its progress throughout the year and week by using two numbers which are the coordinates of a path along a circle. That is,
</p>

<p>
\[ \text{Date \& Time} \mapsto \text{Day of Week} \mapsto (\sin(\text{Day of Week}), \cos(\text{Day of Week})) \]
</p>

<p>
For example,
</p>

<p>
\[ \text{2022-06-22} \to \text{Monday} = 0 \to (\cos(0), \sin(0)) = (1,0) \]
</p>

<p>
We will construct the same measure similarly for how far along the year we are.
</p>
</div>
</div>
<div id="outline-container-org9d90c66" class="outline-4">
<h4 id="org9d90c66"><span class="section-number-4">2.5.3.</span> Categorical Data</h4>
<div class="outline-text-4" id="text-2-5-3">
<p>
Domain knowledge indicates that holidays would have a different power demand behavior than school days. Hence, the model is also fed information of what type the current day is and what the next days type will be. The model would not know if one week has a three day weekend for example.
</p>

<p>
To represent categorical data, a standard approach is to use one-hot encoding. We will input the current day type and the next day type as inputs.
</p>
</div>
</div>
<div id="outline-container-orga5a98b7" class="outline-4">
<h4 id="orga5a98b7"><span class="section-number-4">2.5.4.</span> Temperature Data</h4>
<div class="outline-text-4" id="text-2-5-4">
<p>
The FROG buildings on campus have sensors relating to weather data. This includes:
</p>

<ul class="org-ul">
<li>Temperature</li>
<li>Humidity</li>
<li>Global Horizontal Irradiance</li>
</ul>

<p>
These will be included into the table.
</p>
</div>
</div>
<div id="outline-container-org3814068" class="outline-4">
<h4 id="org3814068"><span class="section-number-4">2.5.5.</span> Standardization</h4>
<div class="outline-text-4" id="text-2-5-5">
<p>
We will standardize all of our input features according to the following:
</p>

<p>
\[ \text{Normalized Feature} = \frac{\text{Feature}- \mu}{\sigma} \]
</p>


<p>
Where \( \mu \) is the mean of the training dataset and \( \sigma \) is the standard deviation from the training dataset. It is important to use the training dataset statistics for the test and validation data to make sure none of their features get leaked into the training / feature engineering pipeline.
</p>
</div>
</div>
<div id="outline-container-orge2f32b3" class="outline-4">
<h4 id="orge2f32b3"><span class="section-number-4">2.5.6.</span> Final Dataset</h4>
<div class="outline-text-4" id="text-2-5-6">
<p>
By appending all of the features we are left with the following dataset.
</p>


<div id="orge69648a" class="figure">
<p><img src="media/post_power_dataframe_all_features.png" alt="post_power_dataframe_all_features.png" />
</p>
</div>

<p>
After preprocessing the dataframe looked like this
</p>
</div>
</div>
</div>
<div id="outline-container-org77a8546" class="outline-3">
<h3 id="org77a8546"><span class="section-number-3">2.6.</span> Models Considered</h3>
<div class="outline-text-3" id="text-2-6">
<p>
This paper aims to further analyze the results in Sachin et. al. by considering different LSTM architectures. Rather than building one layer with 100 units, we look at the performance of nested hidden layers (each with 100 units) and of one large shallow LSTM layer. As a baseline and with further inspiration from Sachin et. al, we compare the LSTM architectures to the SARIMAX model. 
</p>
</div>
</div>
<div id="outline-container-org7259b8f" class="outline-3">
<h3 id="org7259b8f"><span class="section-number-3">2.7.</span> Data Split</h3>
<div class="outline-text-3" id="text-2-7">
<p>
We split the data into train, validation, test with proportions 90 / 5 / 5. The goal is to forecast data in the future, we take the last 10 percent as the data to measure the effectiveness of the model. This is in contrast to an approach which takes the last week of each month as validation and testing data. The training data is in quite large proportion compared to the test and validation data due to the need to include all types of day types into the training set. A lot of papers use a split of 75 or 80 percent for training, however this results in <code>NA</code> values during the normalization <code>day_type</code> for the finals column. In the future, when we collect more data this issue can be avoided.
</p>
</div>
</div>
<div id="outline-container-org5de3d9c" class="outline-3">
<h3 id="org5de3d9c"><span class="section-number-3">2.8.</span> Hyperparameter Search Space &amp; Optimization</h3>
<div class="outline-text-3" id="text-2-8">
</div>
<div id="outline-container-orgc0e4f05" class="outline-4">
<h4 id="orgc0e4f05"><span class="section-number-4">2.8.1.</span> SARIMAX</h4>
<div class="outline-text-4" id="text-2-8-1">
<p>
The SARIMAX model depends on the order and seasonal order hyperparameters. These are tuples \( \text{Order} = (p,q,r), \text{Seasonal Order} = (P,Q,R,s) \) which we choose to keep \( s = 12 \) and let \( p,q,r,P,Q,R \) range over the values \( {0,1} \). In order to find the best orders, we run a for loop through every combination and pick out which order reduces the validation dataset mean squared error.
</p>
</div>
</div>
<div id="outline-container-org08f38f9" class="outline-4">
<h4 id="org08f38f9"><span class="section-number-4">2.8.2.</span> LSTM - Deep &amp; Broad</h4>
<div class="outline-text-4" id="text-2-8-2">
<p>
LSTM is a layer architecture in a larger artificial neural network. This paper explores the effectiveness of stacking multiple layers as opposed to a larger single layer. The hyper parameter for the deep architecture is the number of hidden layers. Where each hidden layer is composed of an LSTM layer with 100 units followed by a batch normalization layer. The broad LSTM model has the number of units in the first hidden LSTM layer. 
</p>
</div>
</div>
</div>
<div id="outline-container-org0419049" class="outline-3">
<h3 id="org0419049"><span class="section-number-3">2.9.</span> Evaluation on Test Set</h3>
<div class="outline-text-3" id="text-2-9">
<p>
The SARIMAX model has the mean squared error on the test set as: \( 3.6651201716716453 \). 
We may summarize the LSTM models in the following two tables.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">LSTM Number Hidden Layers</th>
<th scope="col" class="org-right">Test MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">0.689027</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">0.743700</td>
</tr>

<tr>
<td class="org-right">2</td>
<td class="org-right">0.910402</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-right">1.654828</td>
</tr>

<tr>
<td class="org-right">4</td>
<td class="org-right">0.929098</td>
</tr>

<tr>
<td class="org-right">5</td>
<td class="org-right">0.800219</td>
</tr>

<tr>
<td class="org-right">6</td>
<td class="org-right">0.987502</td>
</tr>

<tr>
<td class="org-right">7</td>
<td class="org-right">1.141009</td>
</tr>

<tr>
<td class="org-right">8</td>
<td class="org-right">0.827337</td>
</tr>

<tr>
<td class="org-right">9</td>
<td class="org-right">0.744342</td>
</tr>

<tr>
<td class="org-right">10</td>
<td class="org-right">0.696265</td>
</tr>
</tbody>
</table>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">LSTM Units - Broad</th>
<th scope="col" class="org-right">Test MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">100</td>
<td class="org-right">1.337295</td>
</tr>

<tr>
<td class="org-right">200</td>
<td class="org-right">1.516799</td>
</tr>

<tr>
<td class="org-right">300</td>
<td class="org-right">1.576121</td>
</tr>

<tr>
<td class="org-right">400</td>
<td class="org-right">1.362951</td>
</tr>

<tr>
<td class="org-right">500</td>
<td class="org-right">1.738935</td>
</tr>

<tr>
<td class="org-right">600</td>
<td class="org-right">1.279818</td>
</tr>

<tr>
<td class="org-right">700</td>
<td class="org-right">1.248263</td>
</tr>

<tr>
<td class="org-right">800</td>
<td class="org-right">3.402421</td>
</tr>

<tr>
<td class="org-right">900</td>
<td class="org-right">2.102972</td>
</tr>

<tr>
<td class="org-right">1000</td>
<td class="org-right">1.793419</td>
</tr>

<tr>
<td class="org-right">1100</td>
<td class="org-right">1.217969</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-org0eb3126" class="outline-3">
<h3 id="org0eb3126"><span class="section-number-3">2.10.</span> Explanation on Differences Between Train / Test Datasets</h3>
<div class="outline-text-3" id="text-2-10">
<p>
In the LSTM models, the loss on the training and validation datasets would go below \( 0.05 \) . However, the training data would have a mean squared error score larger than \( 1 \). I believe this is due to the training set being farther away temporally than the validation dataset. Also we do not have a lot of data to justify many annual trends in the data. Had the training dataset been larger, the model could have had the capability to predict more accurately what would happen in the testing dataset. When looking at the training history, there is an upward drift of the validation loss while the training loss tends to zero. This is indicative of an overfitting regime.
</p>
</div>
</div>
<div id="outline-container-org3593b42" class="outline-3">
<h3 id="org3593b42"><span class="section-number-3">2.11.</span> Discussion</h3>
<div class="outline-text-3" id="text-2-11">
<p>
In this paper, we have found several models based on the LSTM architecture which can beat out SARIMAX, a standard time series regression model. There is a lot of room for improvement and future work. As with most ANN architectures, many knobs and dials may be changed to see what sticks.
</p>

<p>
Vijayaprabakaran et. al. compared different activation functions for the LSTM network. They find that the <code>swish</code> activation function \( \text{swish}(x) = x \cdot \text{sigmoid}(x) \) outperforms the hyperbolic tangent activation function on all of the datasets tested. In trying to use the <code>swish</code> activation function, the model outputs <code>NAN</code> loss, indicative of exploding gradients. Introducing L1, L2 regularization, decreasing the learning rate, and using gradient clipping did not stop the model from eventually reporting <code>NAN</code> during training.
</p>

<p>
There has been a lot of missing data or data that has been thrown out due to creating shape restrictions. Because a future goal of the University is to create a dashboard using the predictions, a future improvement is to handle missing values differently. One approach to missing values is to smooth out the data using an exponential moving average. Another approach is to reconstruct the missing data using the other buildings which hopefully do have their true data being reported. We may impute missing values by placing a value of <code>-1</code> for the missing features. 
</p>

<p>
The features could have also been engineered differently. Rather than using one-hot encoding, one may also try another encoding technique like label encoding. The weather data could also be more precise in regards to the building one wishes to forecast on by using ArcGIS data given the specific coordinates rather than using one building model the weather for another building across campus.
</p>

<p>
We may also re-attempt this process given some extra time to collect more data. Many trends are periodic with respect to the year. Having multiple years worth of data could help the model pick out the trends.
</p>
</div>
</div>
<div id="outline-container-orgbe73f0b" class="outline-3">
<h3 id="orgbe73f0b"><span class="section-number-3">2.12.</span> References</h3>
<div class="outline-text-3" id="text-2-12">
<p>
A Bill for an act - capitol.hawaii.gov. (n.d.).
<a href="https://www.capitol.hawaii.gov/sessions/session2023/bills/HB1509_CD1_.pdf">https://www.capitol.hawaii.gov/sessions/session2023/bills/HB1509_CD1_.pdf</a> <br />
</p>

<p>
Sachin, M. M., Baby, M. P., &amp; Ponraj, A. S. (2020, December). Analysis of energy consumption using RNN-LSTM and ARIMA Model. In Journal of Physics: Conference Series (Vol. 1716, No. 1, p. 012048). IOP Publishing. <br />
</p>

<p>
Vijayaprabakaran, K., &amp; Sathiyamurthy, K. (2022). Towards activation function search for long short-term model network: A differential evolution based approach. Journal of King Saud University-Computer and Information Sciences, 34(6), 2637-2650.
</p>
</div>
</div>
</div>
</div>
</body>
</html>

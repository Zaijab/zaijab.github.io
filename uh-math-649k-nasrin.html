<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-10-03 Thu 14:13 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>UH MATH 649K Nasrin</title>
<meta name="author" content="Zain Jabbar" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>

          <link rel="stylesheet" href="static/css/site.css" type="text/css"/>
          <header><div class="menu"><ul>
          <li><a href="/">/</a></li>
          <li><a href="/about">/about</a></li>
          <li><a href="/posts">/posts</a></li></ul></div></header>
          <script src="static/js/nastaliq.js"></script>
          <script src="static/js/stacking.js"></script>
          <link href='https://unpkg.com/tippy.js@6.2.3/themes/light.css' rel='stylesheet'>
          <script src="https://unpkg.com/@popperjs/core@2"></script>
          <script src="https://unpkg.com/tippy.js@6"></script>
          <script>
          document.addEventListener('DOMContentLoaded', function() {
            let page = document.querySelector('.page');
            if (page) {
              initializePreviews(page);
            }
          });
          </script>
<script>MathJax = { loader: { load: ['[custom]/xypic.js'], paths: {custom: 'https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/'} }, tex: { packages: {'[+]': ['xypic']}, macros: { R: "{\\bf R}" } } };</script><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js"></script>
<div class="grid-container"><div class="ds-grid"><div class="page">
<script>MathJax = { loader: { load: ['[custom]/xypic.js'], paths: {custom: 'https://cdn.jsdelivr.net/gh/sonoisa/XyJax-v3@3.0.1/build/'} }, tex: { packages: {'[+]': ['xypic']}, macros: { R: "{\\bf R}" } } };</script><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml-full.js"></script>
</head>
<body>
<div id="content" class="content">
<h1 class="title">UH MATH 649K Nasrin</h1>
<p>
Class at <a href="university-of-hawaii-at-manoa.html#ID-2728f603-9489-4920-bdf6-e56ea4c5c6de">University of Hawaii at Manoa</a>.
</p>
<div id="outline-container-orgde92c42" class="outline-2">
<h2 id="orgde92c42"><span class="section-number-2">1.</span> MATH 649K Nasrin</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org52f96c7" class="outline-3">
<h3 id="org52f96c7"><span class="section-number-3">1.1.</span> Homework 1</h3>
<div class="outline-text-3" id="text-1-1">
</div>
<div id="outline-container-org8dc112d" class="outline-4">
<h4 id="org8dc112d"><span class="section-number-4">1.1.1.</span> Problem 1</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
\(\lambda\)
</p>
<ul class="org-ul">
<li>\((\Omega, \mathcal{F}, P)\) be a probability space</li>
<li>\(|A| \leq \mathbb{N}\)</li>
<li>\(X \colon \Omega \to A\) be a random variable</li>
<li>\(g \colon A \to [0, \infty]\)</li>
</ul>



<p>
\(\therefore\)
</p>

<p>
Let \(Y=g(X)\), then,
\[\begin{align*}
\mathbb{E}[Y]
&= \sum_{y \in Y} y P(Y = y) \\
&= \sum_{y \in Y} y \sum_{x \in g^{-1}[y]} P(X = x) \\
&= \sum_{y \in Y} \sum_{x \in g^{-1}[y]} g(x) P(X = x) \\
\end{align*}\]  
Note: \(\{y\}\) is a partition of \(\text{im}(g)\) hence \(g^{-1}(y)\) forms a partition of \(X\).
Hence: \[ \sum_{y \in Y} \sum_{x \in g^{-1}[y]} \simeq \sum_{x \in X} \]
So we have the desired result, \[ \sum_{x \in X} g(x) P(X = x) \] 
</p>
</div>
</div>
<div id="outline-container-org75c789e" class="outline-4">
<h4 id="org75c789e"><span class="section-number-4">1.1.2.</span> Problem 2</h4>
<div class="outline-text-4" id="text-1-1-2">
<p>
\(\lambda\)
</p>
<ul class="org-ul">
<li>\(\{E_n\}_{n=1}^{\infty}\) be a sequence of independent events</li>
</ul>

<p>
Note that \(\left\{\bigcap_{n = 1}^{i} E_n \right\}_{i = 1}^{\infty}\)  is a decreasing sequence of events. 
</p>

<p>
\[ P(\bigcap_{n = 1}^{\infty} E_n)
= P(\lim_{i \to \infty} \bigcap_{n = 1}^{i} E_n) \\
= \lim_{i \to \infty} P( \bigcap_{n = 1}^{i} E_n) \\
= \lim_{i \to \infty} \prod_{n = 1}^{i} E_n = \prod_{n = 1}^{\infty} P(E_n)\] 
</p>
</div>
</div>
<div id="outline-container-org70b5099" class="outline-4">
<h4 id="org70b5099"><span class="section-number-4">1.1.3.</span> Problem 3</h4>
<div class="outline-text-4" id="text-1-1-3">
<p>
\(\lambda\)
</p>
<ul class="org-ul">
<li>\(T\) be the text "A Chronicle of Ancient Sunlight", partition \(\mathbb{N}\) by the residue classes \(\mod \ell (T)\) (the length of \(T\))</li>
<li>\(E_k \in \mathcal{F}\) be the event that $T $begins at position \(k \cdot \ell (T)\)</li>
</ul>

<p>
\[ \forall k \in \mathbb{N} . P(E_k) = \frac{1}{K^{\ell(T)}} > 0 \]
</p>

<p>
Thus, \[ \sum_{k \in \mathbb{N}} P(E_k) = \infty \] and \[ \{E_k\}_{k \in \mathbb{N}} \] are an independent set of events.
</p>

<p>
Hence by Borel-Cantelli we have that \[ P(\{E_k \ \text{i.o.} \}) = 1 \] The chimp will almost surely write the novel.
(Infinitely many times in fact; what a hard worker!)
</p>
</div>
</div>
<div id="outline-container-org6b7f8b4" class="outline-4">
<h4 id="org6b7f8b4"><span class="section-number-4">1.1.4.</span> Problem 4</h4>
<div class="outline-text-4" id="text-1-1-4">
\begin{align*}

p \left(\left|\frac{1}{n} \sum_{m = 1}^{n} (X_m - \mathbb{E}(X_m))\right| \geq \delta \right) \\
&\leq \frac{1}{\delta^2} \mathbb{E}\left[ \left| \frac{1}{n} \sum_{m = 1}^{n} (X_m - \mathbb{E}(X_m)) \right|^2 \right] \\
&\leq \frac{1}{\delta^2 n^2} \mathbb{E}\left[ \left| \sum_{m = 1}^{n} (X_m - \mathbb{E}(X_m)) \right|^2 \right] \\
&\leq \frac{1}{\delta^2 n^2} \mathbb{E}\left[ \sum_{m = 1}^{n} (X_m - \mathbb{E}(X_m))^2 \right] \\
&= \frac{1}{\delta^2 n^2} \sum_{m = 1}^{n} \mathbb{E}\left[  (X_m - \mathbb{E}(X_m))^2 \right] \\
&= \frac{1}{\delta^2 n^2} \sum_{m = 1}^{n} \right( \mathbb{E}\left[  (X_m - \mathbb{E}(X_m))^2 \right] + \mathbb{E}\left[  (X_m - \mathbb{E}(X_m)) \right]^2 \right) \\
&= \frac{1}{\delta^2 n^2} \sum_{m=1}^{n} \text{Var}(X_m)
\end{align*}
</div>
</div>
<div id="outline-container-org2f5803d" class="outline-4">
<h4 id="org2f5803d"><span class="section-number-4">1.1.5.</span> Problem 5</h4>
<div class="outline-text-4" id="text-1-1-5">
<ul class="org-ul">
<li>a</li>
</ul>
<p>
We get that \(Y_n\) is the result of pulling all coins out of the barrel.
This means that \(P(Y_n = j) = 0\) when \(j\) is not the number of silver coins and \(1\) when \(j\) is the number of silver coins.
</p>

<p>
\[ P(Y_n = j) = \sum_{i \in [0 .. n]} P(Y_n = j \vert \ i \text{ Silver Coins}) P(i \text{ Silver Coins}) = \frac{1}{n+1} \] 
</p>

<ul class="org-ul">
<li>b</li>
</ul>
<p>
Let us condition on two properties, \[ Y_n = i \] and that the "Next coin is Silver = S" or "Next coin is Gold = G".
</p>

<p>
\[\begin{align*}
P(Y_{n-1} = j)
&= \sum_{i \in [0 .. n]} P(Y_{n-1} = j \vert S \land \ Y_n = i) P(S \land Y_n = i) \\
&+ P(Y_{n-1} = j \vert G \land \ Y_n = i) P(G \land Y_n = i) \\
&= \sum_{i \in [0 .. n]} P(Y_{n-1} = j \vert S \land \ Y_n = i) P(S \vert Y_n = i) P(Y_n = i) \\
&+ P(Y_{n-1} = j \vert G \land \ Y_n = i) P(G \vert Y_n = i) P(Y_n = i) \\
\end{align*}\]
Now we may evaluate some of the expressions.
\[ P(Y_{n-1} = j \vert S \land \ Y_n = i) = \begin{cases} 1 & j = i-1 \\ 0 & \text{else} \end{cases} \] 
\[ P(Y_{n-1} = j \vert G \land \ Y_n = i) = \begin{cases} 1 & j = i \\ 0 & \text{else} \end{cases} \] 
\[ P(S \vert \ Y_n = i) =  \frac{i}{n} \] 
\[ P(G \vert \ Y_n = i) =  \frac{n - i}{n} \]
\[ P(Y_n = i) = \frac{1}{n+1} \]
</p>

<p>
Due to the first two equations, we get a lot of zero terms. There are only two cases when there are non zero terms. That being when \[ i = j \] and \[ i = j + 1 \] 
So the sum becomes \[ 1 \cdot \frac{j + 1}{n} \cdot \frac{1}{n + 1} + 1 \cdot \frac{n - j}{n} \cdot \frac{1}{n+1} = \frac{1}{n} \]
</p>

<ul class="org-ul">
<li>c</li>
</ul>
<p>
I conjecture:
\[ P(Y_{k} = i) = \frac{1}{k+1} \] 
</p>


<ul class="org-ul">
<li>d</li>
</ul>

<p>
We can calculate this similarly to part (b) (and by similarly, I mean I literally copy pasted the result and did a search and replace)
</p>


<p>
Let us condition ok two properties, \[ Y_k = i \] and that the "Next coin is Silver = S" or "Next coin is Gold = G".
</p>

<p>
\[ \begin{align*}
P(Y_{k-1} = j)
&= \sum_{i \in [0 .. k]} P(Y_{k-1} = j \vert S \land \ Y_k = i) P(S \land Y_k = i)\\ &+ P(Y_{k-1} = j \vert G \land \ Y_k = i) P(G \land Y_k = i) \\
&= \sum_{i \in [0 .. k]} P(Y_{k-1} = j \vert S \land \ Y_k = i) P(S \vert Y_k = i) P(Y_k = i)\\ &+ P(Y_{k-1} = j \vert G \land \ Y_k = i) P(G \vert Y_k = i) P(Y_k = i) \\
\end{align*}\]
Now we may evaluate some of the expressions.
\[ P(Y_{k-1} = j \vert S \land \ Y_k = i) = \begin{cases} 1 & j = i-1 \\ 0 & \text{else} \end{cases} \] 
\[ P(Y_{k-1} = j \vert G \land \ Y_k = i) = \begin{cases} 1 & j = i \\ 0 & \text{else} \end{cases} \] 
\[ P(S \vert \ Y_k = i) =  \frac{i}{k} \] 
\[ P(G \vert \ Y_k = i) =  \frac{k - i}{k} \]
\[ P(Y_k = i) = \frac{1}{k+1} \]
</p>

<p>
Due to the first two equations, we get a lot of zero terms. There are only two cases when there are non zero terms. That being when \[ i = j \] and \[ i = j + 1 \] 
So the sum becomes \[ 1 \cdot \frac{j + 1}{k} \cdot \frac{1}{k + 1} + 1 \cdot \frac{k - j}{k} \cdot \frac{1}{k+1} = \frac{1}{k} \]
</p>
</div>
</div>
<div id="outline-container-orge500062" class="outline-4">
<h4 id="orge500062"><span class="section-number-4">1.1.6.</span> Problem 6</h4>
<div class="outline-text-4" id="text-1-1-6">
<ul class="org-ul">
<li>a</li>
</ul>
<p>
Let \(P_{n,m} := P(A \text{ is always ahead} \vert \ [A \text{ has } n \text{ votes}] \land [B \text{ has } m \text{ votes}])\)
</p>

<p>
Then \(1 - P_{m,n}\) is the probability of the negation; thus \(1 - P_{m,n} = P(A \text{ is not always ahead} \vert \ [A \text{ has } n \text{ votes}] \land [B \text{ has } m \text{ votes}])\)
If there is a point where \(A\) is not always ahead, then there exists a time where \(A\) is tied with \(B\). Hence, \(1 - P_{m,n} = P(A \text{ is at some point tied with } B \vert \ [A \text{ has } n \text{ votes}] \land [B \text{ has } m \text{ votes}])\)
</p>


<ul class="org-ul">
<li>b</li>
</ul>
<p>
We know that \(A\) eventually wins due to \(n > m\). Hence any sequence that begins with \(B\) will eventually tie. Also any sequence that begins with \(A\) can be put in put in bijection with a sequence starting with \(B\). This is because any sequence that ties with \(A\) starting can be flipped (A to B and B to A) into a sequence beginning with \(B\) and eventually tying. This is has an inverse, hence bijective.
</p>

<p>
Note: \(A\) and \(B\) cannot tie in the first vote because either \(A\) or \(B\) gets one vote and the other has zero. So someone is ahead on the first vote.
If \(A\) and \(B\) eventually tie, then there is one person who was ahead of the other, then there was one vote that tied them. Call the first such case the \(n\) th vote. Both are tied on the \(n\) th vote.
If one person was ahead of another, and they tie, that means the person that was behind was the one that got the \(n\) th vote.
</p>

<p>
Hence, the one who was ahead gets the first vote and the person who was behind gets the \(n\) th vote.
</p>

<p>
By reversing the order of the votes, we get a dual case where the person who was ahead in the original case is now the person who was behind in the dual case. This is a bijection of cases hence it does not matter who gets the first vote.
</p>

<ul class="org-ul">
<li>c</li>
</ul>
<p>
We prove this by counting.
</p>

<p>
\[ P(T) = \frac{\text{No. of Sequences with Ties}}{\text{No. of Sequences}} \] 
</p>

<p>
Let \(t\) be the number of sequences that end have ties. Each sequence is determined by the places where \(n\) votes for \(A\) are given.  
</p>

<p>
The probability of tying is \[ P(T) = P(T \land A) + P(T \land B) = 2 \cdot P(T \land B) \]
</p>

<p>
\[ P(T) = 2 \cdot P(T | B) P(B) \] because there is a bijection between tying sequences beginning with \(A\) or \(B\). Because \(A\) always wins we know \(P(T | B) = 1\) hence \(P(T) = 2 \cdot \frac{m}{m + n}\).
</p>

<p>
Thus
\[ \begin{align*}
P_{n,m}
&= 1 - P(\text{Sequence eventually ties}) \\
&= 1 - 2 \cdot P(\text{Sequence begins with }B) \\
&= 1 - 2 \frac{m}{m+n} \\
&= \frac{n - m}{m+n} \\
\end{align*}\] 
</p>
</div>
</div>
</div>
<div id="outline-container-orgadd5735" class="outline-3">
<h3 id="orgadd5735"><span class="section-number-3">1.2.</span> Homework 2</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org0d36c60" class="outline-4">
<h4 id="org0d36c60"><span class="section-number-4">1.2.1.</span> Problem 1</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
\( \lambda \)
</p>
<ul class="org-ul">
<li>\( \{N(t), t \geq 0 \} \) be a PP with rate \( \lambda > 0 \)</li>
<li>\( G \) be a non-negative random variable with mean \( \mu \) and variance \( \sigma^2 \)</li>
<li>\( G \) be independent of \( N(t) \)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org9ed1d8e"></a>A<br />
<div class="outline-text-5" id="text-1-2-1-1">
<p>
\( \Cov(G,N(G)) = \E[G \cdot N(G)] - \E[N(G)] \E[G] \)
</p>

<p>
We shall condition on \( G \).
</p>

<p>
\[ \E[G \cdot N(G)] = \E[\E[G \cdot N(G) \vert G]] = \E[G \cdot \lambda G]\]
\[ \E[N(G)] = \E[\E[ N(G) \vert G]] = \E[\lambda G] \]
Both of these calculations use \( \E[N(t)] = \lambda t \), when given \( G \) we can substitute in \( G \) for t.
Thus,
\( \Cov(G, N(G)) = \lambda (\E[G^2] - \E[G]^2) = \lambda \Var[G] = \lambda \sigma^2 \) 
</p>
</div>
</li>
<li><a id="org037e94a"></a>B<br />
<div class="outline-text-5" id="text-1-2-1-2">
\begin{align*}
\Var[N(G)] &= \E[\E[N(G)^2 \vert G]] - \E[\E[N(G) \vert G]]^2  \\
&= \E[\lambda^2 G^2 + \lambda G] - \E[\lambda G]^2  \\
&= \E[\lambda^2 G^2] - \E[\lambda G]^2 + \E [\lambda G]   \\
&= \lambda^2 \Var[G] + \lambda \E[G]
\end{align*}
</div>
</li>
</ol>
</div>
<div id="outline-container-org2162678" class="outline-4">
<h4 id="org2162678"><span class="section-number-4">1.2.2.</span> Problem 2</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
\( \lambda \)
</p>
<ul class="org-ul">
<li>\( \{N(t), t \geq 0 \} \) be a PP (Using Definition 2.1.2) with rate \( \lambda \)</li>
<li>\( I \) be an interval of length \( t \)</li>
</ul>

<p>
Calculate the Laplace Transform of \( N(t) \)
</p>
\begin{align*}
F(t + h)
&= \E[e^{-s N(t + h)}] \\
&= \E[e^{-s (N(t) + (N(t+h) - N(t)))}] \\
&= \E[e^{-s N(t)} e^{-s (N(t+h) - N(t)}] \\
&= \E[e^{-s N(t)}] \E[e^{-s (N(t+h) - N(t)}] \\
&= F(t) \E[e^{-s (N(h))}] \\
\end{align*}
<p>
First equality is calculating the laplace transform and defining a function \( F \) to be the value of the laplace transform at \( x \).
Second equality is by using the properties of counting process.
Third equality is using properties of exponentials.
Fourth equality is using independence of increments.
Last equality is noticing that we have another term of the laplace transform. This gives us a functional relationship which will be used to actually solve for the values of \( F \).
</p>

<p>
To find the value of \( \E[e^{-s (N(h))}] \) we may condition on the value of \(N(h)\). This formatting looks gross sorry about that :(
</p>

\begin{align*}
\E[e^{-s (N(h))}]
&= \E[\E[e^{-s (N(h))} \vert N(h)]]\\
&= \E[e^{-s (N(h))} \vert N(h) = 0] P(N(h) = 0) + \\
&\E[e^{-s (N(h))} \vert N(h) = 1] P(N(h) = 1) + \\
&\E[e^{-s (N(h))} \vert N(h) \geq 2] P(N(h) \geq 2) \\
&= 1 \cdot (1 - (\lambda h + o(h) + o(h))) + e^{-s} (\lambda h + o(h)) + \sum_{i = 2}^{\infty} e^{-s \cdot i} P(N(h) = i) \\
&= 1 - \lambda h + e^{-s} \lambda h + o(h)
\end{align*}
<p>
We use three cases, \( n=0,1,\geq 2 \). These cases are motivated by the given definition of our process.
We then apply the properties of the process for the case of \( 0 \) and \( 1 \) and use summations for greater than \( 2 \).
Using the properties of the poisson process again and combining like terms we get the last equality.
</p>

<p>
Hence:
</p>

<p>
\(F(t + h) = F(t) (1 - \lambda h + e^{-s} \lambda h + o(h))\)
</p>

<p>
\(\implies\) \(\frac{F(t + h) - F(t)}{h} = F(t)(-\lambda + e^{-s} \lambda) + \frac{o(h)}{h}\)
</p>

<p>
By letting \(h \to 0\) we obtain, \(F'(t) = F(t)(-\lambda + e^{-s} \lambda)\)
</p>

<p>
Rearanging: \(\frac{F'(t)}{F(t)} = \lambda (-1 + e^{-s})\)
</p>

<p>
Integrating by \(t\) yields: \(\log(F(t)) = \lambda t (-1 + e^{-s})\)
</p>

<p>
So: \(F(t) = e^{\lambda t (-1 + e^{-s})}\) which is the Laplace transform of a Poisson random variable.
</p>

<p>
By uniqueness of the Laplace transform we get that \(N(t)\) is a Poisson random variable.
</p>
</div>
</div>
<div id="outline-container-org2139254" class="outline-4">
<h4 id="org2139254"><span class="section-number-4">1.2.3.</span> Problem 3</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
\( \lambda \)
</p>
<ul class="org-ul">
<li>\( \psi_i(t) \) be the indicator function of bug \( i \) causing an error by \( t \)</li>
</ul>

<p>
First, \( \E[M_2(t)] \), I'll use it in the next proof.
We use a different indicator function, \( I_i^{(2)} \) indicates bug \( i \) causes \( 2 \) errors. This is Poisson Distributed.
</p>

\begin{align*}
\E[M_2(t)]
&= \sum_i \E[I_i^{(2)}(t)] \\
&= \sum_{i} e^{-\lambda_i t} \frac{(\lambda_i t)^2}{2}
\end{align*}

\begin{align*}
\E\left[\left(\Lambda(t) - \frac{M_1(t)}{t}\right)^2\right]
&= \E\left[\left(\Lambda(t) - \frac{M_1(t)}{t}\right)^2\right] + 0 \\
&= \E\left[\left(\Lambda(t) - \frac{M_1(t)}{t}\right)^2\right] + \E\left[\left(\Lambda(t) - \frac{M_1(t)}{t}\right)\right]^2 \\
&= \Var[\Lambda(t) - \frac{M_1(t)}{t}] \\
&= \Var[\Lambda(t)] + \frac{\Var(M_1(t))}{t^2} - \frac{2}{t} \Cov(\Lambda(t), M_1(t)) \\
&= [\sum_i \lambda_i^2 (e^{-\lambda_i t})(1-e^{-\lambda_i t})] + \\
&\frac{[\sum_i (\lambda_i t e^{-\lambda_i t}) (1 - \lambda_i t e^{-\lambda_i t})]}{t^2} - \frac{2}{t} [\sum_i \Cov(\psi_i(t), I_i(t))] \\
&= [\sum_i \lambda_i^2 (e^{-\lambda_i t})(1-e^{-\lambda_i t})] + \\
&\frac{[\sum_i (\lambda_i t e^{-\lambda_i t}) (1 - \lambda_i t e^{-\lambda_i t})]}{t^2} - \frac{2}{t} [\sum_i \lambda_i e^{-\lambda_i t} \lambda_i t e^{-\lambda_i t}] \\
&= \sum_i \lambda_i^2 e^{- \lambda_i t} + \frac{\sum_i \lambda_i e^{-\lambda_i t}}{t} \\
&= \frac{\E[M_1(t) + 2 M_2(t)]}{t^2} \\
\end{align*}

<p>
First equality is by adding 0.
Second equality is by using \( \E[\Lambda(t) - \frac{M_1(t)}{t}] = 0 \) (we proved this in class). Hence \( \E\left[\left(\Lambda(t) - \frac{M_1(t)}{t}\right)\right]^2 = 0 \).
Third equality is from \( \Var(X) = \E[X^2] - \E[X]^2 \).
Fourth equality is by using definition of \( \Var \) for possibly non independent random variables.
Fifth equality is from breaking down \( \Lambda \) and \( M_1 \) into their summation forms and applying the variance to all of the terms.
Sixth equality is calculating the covariance between the summands.
Seventh equality is combining terms with the same index \( i \).
Last equality is to notice the two sums are the definitions of \( M_1 \) and \( 2M_2 \) (Which is only motivated because that was what we wanted to show). 
</p>
</div>
</div>
<div id="outline-container-org6f9a621" class="outline-4">
<h4 id="org6f9a621"><span class="section-number-4">1.2.4.</span> Problem 4</h4>
<div class="outline-text-4" id="text-1-2-4">
<p>
\( \lambda \)
</p>
<ul class="org-ul">
<li>\( N(t) \) be a non-homogeneous Poisson Process with rate \( \lambda(t) \)</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org0695ac0"></a>A<br />
<div class="outline-text-5" id="text-1-2-4-1">
<p>
\( \lambda(t) = \begin{cases} 6 & 0 \leq t < 2 \\ 15 & 2 \leq t < 4 \\ 15 - (\frac{5}{2})(t-4) & 4 \leq t \leq 6 \end{cases} \)
From this we can define \( m(t) \)
</p>

<p>
\( m(t) = \begin{cases} 6t & 0 \leq t < 2 \\ 15(t-2) + 12 & 2 \leq t < 4 \\ 15(t-4) - (\frac{5}{2})(\frac{1}{2}(t-4)^2-4(t-4)) + 42 & 4 \leq t \leq 6 \end{cases} \)
</p>
</div>
</li>
<li><a id="org5427b1f"></a>B<br />
<div class="outline-text-5" id="text-1-2-4-2">
<p>
Calculate \( m(5) - m(3) = 62.75 \) 
\( P(N(5) - N(3) = 0) = \exp(-62.75) \frac{62.75^0}{0!} \simeq 5.5978500469\cdot 10^{-28}\) 
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org5bd90c7" class="outline-4">
<h4 id="org5bd90c7"><span class="section-number-4">1.2.5.</span> Problem 5</h4>
<div class="outline-text-4" id="text-1-2-5">
<p>
\( \lambda \)
</p>
<ul class="org-ul">
<li>\( M(t) \) be the total amount of money paid in \( (0,t] \)</li>
<li>The number of payments follow a Poisson Process with \( \lambda = 5 \)</li>
<li>The Payments are exponentially distributed with expected value \( 20,000 \)</li>
<li>\( \E[M(4)] \)</li>
</ul>

<p>
We have the following relationship between the terms:
</p>

<p>
\[ M(t) = \sum_{i=0}^{N(t)} P_i \]
Using the formula from the random number of random variables we can calculate the expected value.
</p>

<p>
Hence \( \E[M(t)] = \E[N(t)] \E[P_i] \)
</p>

<p>
\( \E[M(4)] = 5 \cdot 4 \cdot 20,000 = 400,000 \) 
</p>
</div>
</div>
<div id="outline-container-orgebe97a0" class="outline-4">
<h4 id="orgebe97a0"><span class="section-number-4">1.2.6.</span> Problem 6</h4>
<div class="outline-text-4" id="text-1-2-6">
<p>
\( \lambda \)
</p>
<ul class="org-ul">
<li>\(N(t)\) be a Poisson Process with rate \(1\)</li>
<li>\(\Lambda\) be a non negative non constant random variable.</li>
<li>\(N_\Lambda(t) := N(\Lambda t)\), \(N_\Lambda\) is then Poisson with rate \(\lambda\) when conditioning on \(\Lambda = \lambda\)</li>
</ul>

<p>
Suppose for sake of contradiction that \(N_\Lambda(t)\) had independent increments,
</p>

\begin{align*}
P(N_\Lambda(1) - N_\Lambda(0) = 0,N_\Lambda(2) - N_\Lambda(1) = 0) 
&= P(N_\Lambda(1) - N_\Lambda(0) = 0) P(N_\Lambda(2) - N_\Lambda(1) = 0) \\
&= P(N_\Lambda(2) = 0)
\end{align*}

<p>
Calculating \(P(N_\Lambda(1) = 0)\) yields:
</p>

<p>
\(P(N_\Lambda(1)) = \E[P(N(\lambda) = 0 \vert \Lambda = \lambda)] = \E[e^{-\Lambda}]\)
</p>

<p>
By stationary increments we also have
</p>

<p>
\(P(N_\Lambda(2) - N_\Lambda(1)) = \E[P(N(2\lambda) - N(\lambda) = 0 \vert \Lambda = \lambda)] = \E[e^{-\Lambda}]\)
</p>

<p>
Calculating \(P(N_\Lambda(2))\) yields:
</p>

<p>
\(P(N_\Lambda(2)) = \E[P(N(2\lambda) = 0 \vert \Lambda = \lambda)] = \E[e^{-2\Lambda}]\)
</p>

<p>
Hence:
</p>

\begin{align*}
P(N_\Lambda(1) - N_\Lambda(0) = 0) P(N_\Lambda(2) - N_\Lambda(1) = 0)
&= \E[e^{-\Lambda}]^2 \\
&< \E[e^{-2\Lambda}] \\
&= P(N_\Lambda(2) = 0)\\
\end{align*}

<p>
The inequality appears using Jensen's inequality where \( x^2 \) is a convex function.
The inequality is strict due to \(\Lambda\) being non constant in the hypothesis.
</p>
</div>
</div>
</div>
<div id="outline-container-orga85b81f" class="outline-3">
<h3 id="orga85b81f"><span class="section-number-3">1.3.</span> Homework 3</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org4232cd2" class="outline-4">
<h4 id="org4232cd2"><span class="section-number-4">1.3.1.</span> Problem 1</h4>
<div class="outline-text-4" id="text-1-3-1">
</div>
<ol class="org-ol">
<li><a id="org3b2d3b0"></a>A<br />
<div class="outline-text-5" id="text-1-3-1-1">
<p>
Let \( F_{V}(v) \) denote the CDF of \( V \) at \( v \). Note that \( F_U(u) \) for \( U \) uniform from \( [0,1] \) has the property that \( \forall u \in [0,1] . F_U(u) = u \).
</p>

<p>
First we show that the \( CDF \) of \( X_i \) is the same as the CDF of \( \alpha \) for \( i = 0 \).
</p>
\begin{align*}
P(X_0 \leq j)
&= P(U_0 \leq \sum_{m = 1}^j \alpha_m) \\
&= P(U_0 \leq F_\alpha(j)) \\
&= F_\alpha(j)
\end{align*}

<p>
Next we show that the \( CDF \) of \( X_i \) is the same as the CDF of \( q_{X_{i - 1}} \) for \( i > 0 \).
</p>

\begin{align*}
P(X_n \leq j)
&= P(U_n \leq \sum_{m = 1}^j q_{X_{n-1}, m}) \\
&= P(U_n \leq F_{q_{X_{n-1}}}(j)) \\
&= F_{q_{X_{n-1}}}(j)
\end{align*}

<p>
Hence \( X_i \) has the distribution we want.
</p>

<p>
To show that \( X_i \) is a Markov Chain, we need to show that it has the Markov property.
</p>

<p>
Suppose \( X_n = j_n \) then \( X_{n+1} = \inf_{j_{n+1}} U_{n+1} \leq \sum_{m = 1}^{j_{n+1}} q_{i, m} \). So \( X_{n+1} \) only depends on random variables which are also independent of the past. So the Markov property holds. 
</p>
</div>
</li>
<li><a id="org670b657"></a>B<br />
<div class="outline-text-5" id="text-1-3-1-2">
<div class="org-src-container">
<pre class="src src-python3"><span style="color: #531ab6;">import</span> numpy <span style="color: #531ab6;">as</span> np
<span style="color: #531ab6;">import</span> matplotlib.pyplot <span style="color: #531ab6;">as</span> plt

np.random.seed<span style="color: #000000;">(</span>24599253<span style="color: #000000;">)</span>

<span style="color: #595959;"># </span><span style="color: #595959;">Input: Initial Distribution `alpha` and transition matrix `p`</span>
<span style="color: #005e8b;">alpha</span> = np.array<span style="color: #000000;">(</span><span style="color: #dd22dd;">[</span>1/6 <span style="color: #531ab6;">for</span> i <span style="color: #531ab6;">in</span> <span style="color: #8f0075;">range</span><span style="color: #008899;">(</span>6<span style="color: #008899;">)</span><span style="color: #dd22dd;">]</span><span style="color: #000000;">)</span>
<span style="color: #005e8b;">p</span> = np.array<span style="color: #000000;">(</span><span style="color: #dd22dd;">[</span><span style="color: #008899;">[</span>0, 1/3, 2/3, 0, 0, 0<span style="color: #008899;">]</span>,
              <span style="color: #008899;">[</span>1/2, 1/2, 0, 0, 0, 0<span style="color: #008899;">]</span>,
              <span style="color: #008899;">[</span>0, 0, 0, 1/4, 1/2, 1/4<span style="color: #008899;">]</span>,
              <span style="color: #008899;">[</span>0, 1/3, 1/6, 1/6, 1/3, 0<span style="color: #008899;">]</span>,
              <span style="color: #008899;">[</span>0, 0, 0, 0, 1/2, 1/2<span style="color: #008899;">]</span>,
              <span style="color: #008899;">[</span>1/4, 1/2, 1/4, 0, 0, 0<span style="color: #008899;">]</span><span style="color: #dd22dd;">]</span><span style="color: #000000;">)</span>

<span style="color: #595959;"># </span><span style="color: #595959;">Step 1:</span>
<span style="color: #005e8b;">u_0</span> = np.random.uniform<span style="color: #000000;">()</span>

<span style="color: #005e8b;">i</span> = 0
<span style="color: #531ab6;">while</span><span style="color: #000000;">(</span><span style="color: #8f0075;">sum</span><span style="color: #dd22dd;">(</span>alpha<span style="color: #008899;">[</span>:i<span style="color: #008899;">]</span><span style="color: #dd22dd;">)</span> &lt; u_0<span style="color: #000000;">)</span>:
    <span style="color: #005e8b;">i</span> += 1
<span style="color: #005e8b;">x_0</span> = i - 1

<span style="color: #005e8b;">x_n</span> = <span style="color: #000000;">[</span>x_0<span style="color: #000000;">]</span>
<span style="color: #531ab6;">for</span> k <span style="color: #531ab6;">in</span> <span style="color: #8f0075;">range</span><span style="color: #000000;">(</span>10<span style="color: #000000;">)</span>:
    <span style="color: #595959;"># </span><span style="color: #595959;">Step 2:</span>
    <span style="color: #005e8b;">u_n</span> = np.random.uniform<span style="color: #000000;">()</span>

    <span style="color: #595959;"># </span><span style="color: #595959;">Step 3:</span>
    <span style="color: #005e8b;">i</span> = 0
    <span style="color: #531ab6;">while</span><span style="color: #000000;">(</span><span style="color: #8f0075;">sum</span><span style="color: #dd22dd;">(</span>p<span style="color: #008899;">[</span>x_n<span style="color: #972500;">[</span>-1<span style="color: #972500;">]</span>, :i<span style="color: #008899;">]</span><span style="color: #dd22dd;">)</span> &lt; u_n<span style="color: #000000;">)</span>:
        <span style="color: #005e8b;">i</span> += 1
    x_n.append<span style="color: #000000;">(</span>i-1<span style="color: #000000;">)</span>

<span style="color: #005e8b;">_</span> = plt.hist<span style="color: #000000;">(</span>x_n, bins = <span style="color: #dd22dd;">[</span>0,1,2,3,4,5,6<span style="color: #dd22dd;">]</span><span style="color: #000000;">)</span>
</pre>
</div>

<pre class="example">
0 0.10999239911748915 [4] 4 [0.  0.  0.  0.  0.5]
1 0.703630489091046 [4, 4] 4 [0.  0.  0.  0.  0.5]
2 0.08218580690750654 [4, 4, 5] 5 [0.25 0.5  0.25 0.   0.   0.  ]
3 0.24690225782026776 [4, 4, 5, 0] 0 [0.]
4 0.9535197880073909 [4, 4, 5, 0, 1] 1 [0.5 0.5]
5 0.6663585794590124 [4, 4, 5, 0, 1, 1] 1 [0.5 0.5]
6 0.5565583825902818 [4, 4, 5, 0, 1, 1, 1] 1 [0.5 0.5]
7 0.8486494924842696 [4, 4, 5, 0, 1, 1, 1, 1] 1 [0.5 0.5]
8 0.21120786765810307 [4, 4, 5, 0, 1, 1, 1, 1, 1] 1 [0.5 0.5]
9 0.501279767774941 [4, 4, 5, 0, 1, 1, 1, 1, 1, 0] 0 [0.]
</pre>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">array</td>
<td class="org-left">((2 5 1 0 2 1))</td>
<td class="org-left">array</td>
<td class="org-left">((0 1 2 3 4 5 6))</td>
<td class="org-left">&lt;BarContainer</td>
<td class="org-left">object</td>
<td class="org-left">of</td>
<td class="org-right">6</td>
<td class="org-left">artists&gt;</td>
</tr>
</tbody>
</table>

<div id="org4631659" class="figure">
<p><img src="./.ob-jupyter/05c37534cda2384b5d305f194bd834cf44bb7ca7.png" alt="05c37534cda2384b5d305f194bd834cf44bb7ca7.png" />
</p>
</div>
</div>
</li>
</ol>
</div>
<div id="outline-container-org28cedc0" class="outline-4">
<h4 id="org28cedc0"><span class="section-number-4">1.3.2.</span> Problem 2</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
Consider a two-state Markov Chain with state space \( S = \{1,2\} \) and transition matrix \( P = \begin{pmatrix} 1 - p & p \\ q & 1-q \end{pmatrix} \).
</p>

<p>
Denote \( X = \begin{pmatrix} q & p \\ q & p \end{pmatrix} \) which has adjugate matrix \( \adj(X) = \begin{pmatrix} p & -p \\ -q & q \end{pmatrix} \) and determinant \( \det(X) = 0  \).
</p>

<p>
These \( X \) are very well behaved. We may prove some properties about them.
</p>

<p>
First, the definition of \( X \) is motivated by the problem statement.
</p>

\begin{align}
P^{(n)}
&=
\begin{pmatrix}
\frac{q}{p + q} + \frac{p}{p + q}(1 - p - q)^n & \frac{p}{p + q} - \frac{p}{p + q}(1 - p - q)^n \\
\frac{q}{p + q} - \frac{q}{p + q}(1 - p - q)^n & \frac{p}{p + q} + \frac{q}{p + q}(1 - p - q)^n \\
\end{pmatrix} \\
&=
\frac{1}{p + q}
\begin{pmatrix}
q + p(1 - p - q)^n & p - p(1 - p - q)^n \\
q - q(1 - p - q)^n & p + q(1 - p - q)^n \\
\end{pmatrix} \\
&=
\frac{1}{p + q}
\left( X +
\begin{pmatrix}
 p(1 - p - q)^n & - p(1 - p - q)^n \\
- q(1 - p - q)^n & q(1 - p - q)^n \\
\end{pmatrix}
 \right) \\
&=
\frac{1}{p + q}
\left( X + (1 - p - q)^n
\begin{pmatrix}
 p & - p \\
- q & q \\
\end{pmatrix}
 \right) \\
&=
\frac{1}{p + q}
\left( X + (1 - p - q)^n \adj(X)
 \right)
\end{align}

<p>
Second, \( X + \adj(X) = \begin{pmatrix} q + p & 0 \\ 0 & p + q \end{pmatrix} = (p+q) I_2 \)
</p>

<p>
Third, it's helpful to use \( \adj(X) \) because it tells these three facts
</p>
<ul class="org-ul">
<li>\( \adj(X)^2 = \adj(X^2) \)</li>
<li>\( X \adj(X) = \det(X) I = 0 \)</li>
<li>\( \adj(cX) = c \adj(X) \)</li>
</ul>


<p>
We will prove this problem using Induction and all of this preliminary work
</p>

<p>
Formally, we will show:
</p>

<p>
\[ P^{(n)} = \frac{1}{p+q} \left( X + (1 - p - q)^n \adj(X) \right) \]
</p>

<p>
Base Case: \( n = 0 \)
</p>

\begin{align}
P^{(0)}
&= \frac{1}{p + q}(X + (1 - p - q)^0 \adj(X)) \\
&= \frac{1}{p + q}(X + \adj(X)) \\
&= \frac{1}{p + q}((p + q) I_2) \\
&=  I_2 \\
\end{align}

<p>
Inductive Hypothesis: Suppose
</p>

<p>
\[ P^{(n)} = \frac{1}{p+q} \left( X + (1 - p - q)^n \adj(X) \right) \]
</p>

\begin{align*}
P^{(n)}P
&= \frac{1}{p+q} \left( X + (1 - p - q)^n \adj(X) \right) \cdot \frac{1}{p+q} \left( X + (1 - p - q)^1 \adj(X) \right) \\
&= \frac{1}{(p+q)^2} \left( X^2 + (1 - p - q) X \cdot \adj(X) + (1 - p - q)^n \adj(X) X + (1 - p - q)^{n + 1} \adj(X) \adj(X) \right) \\
&= \frac{1}{(p+q)^2} \left( X^2 + (1 - p - q)^{n + 1} \adj(X)^2 \right) \\
&= \frac{1}{(p+q)^2} \left( (p + q)X + (1 - p - q)^{n + 1} \adj(X^2) \right) \\
&= \frac{1}{(p+q)^2} \left( (p + q)X + (1 - p - q)^{n + 1} \adj((p + q)X) \right) \\
&= \frac{1}{(p+q)^2} \left( (p + q)X + (p + q)(1 - p - q)^{n + 1} \adj(X) \right) \\
&= \frac{1}{(p+q)} \left( X + (1 - p - q)^{n + 1} \adj(X) \right) \\
&= P^{(n + 1)}
\end{align*}

<p>
We have that going from one step to the next is just multiplying the transition matrix. First we multiply the two summation forms of \( P \) and distribute. We know that a matrix times its adjugate is the determinant times the identity, in this case it is \( 0 \). We then have nice forms for the squares of \( X \) and \( \adj(X) \) respectively. Performing matrix multiplication verifies that \( X^2 = (p+q) X \). We then use some rules of \( \adj \) from the third note above. Factoring yields the definition of \( P^{(n+1)} \) we wanted proving the induction.
</p>
</div>
</div>
<div id="outline-container-orgb62324e" class="outline-4">
<h4 id="orgb62324e"><span class="section-number-4">1.3.3.</span> Problem 3</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
Consider a discrete time Markov chain with transition matrix \( P = \begin{pmatrix} 1/2 & 1/3 & 1/6 \\ 3/4 & 0 & 1/4 \\ 0 & 1 & 0 \end{pmatrix} \) 
</p>
</div>
<ol class="org-ol">
<li><a id="orge1ab9ed"></a>A<br />
<div class="outline-text-5" id="text-1-3-3-1">
<p>
\( P^{3} = \begin{pmatrix} 1/2 & 1/3 & 1/6 \\ 9/16 & 1/4 & 3/16 \\ 3/8 & 1/2 & 1/8 \end{pmatrix} \) hence irreducible.
\( P_{11} = 1/2 \) implies state \( 1 \) is aperiodic and the chain is irreducible meaning all states are aperiodic.
</p>
</div>
</li>
<li><a id="orgfca1144"></a>B<br />
<div class="outline-text-5" id="text-1-3-3-2">
<p>
\( P^2 \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix} = \begin{bmatrix} 1/2 \\ 1/3 \\ 1/6 \end{bmatrix} \) Hence \( P_{13}^{2} = 1/6 \) 
</p>
</div>
</li>
<li><a id="org677e371"></a>C<br />
<div class="outline-text-5" id="text-1-3-3-3">
<p>
We may diagonalize \( P \) as \( S J S^{-1} \) where
</p>

<p>
\( S =
\begin{pmatrix}
0 & \frac{-1}{3} & 1 \\
\frac{-1}{2} & 0 & 1 \\
1 & 1 & 1
\end{pmatrix} \) 
\( J =
\begin{pmatrix}
\frac{-1}{2} & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 1
\end{pmatrix} \) 
\( S^{-1} =
\begin{pmatrix}
1 & \frac{-4}{3} & \frac{1}{3} \\
\frac{-3}{2} & 1 & \frac{1}{2} \\
\frac{1}{2} & \frac{1}{3} & \frac{1}{6}
\end{pmatrix} \)
</p>

<p>
This is useful as \( P^n = SJ^n S^{-1} \)
</p>

<p>
Taking the limit as \( n \to \infty \) shows \( \pi = S E_{3,3} S^{-1} \)  where \( E \) is the unit matrix with one in row \( 3 \) column \( 3 \), that is \( E = \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix} \). It's worth naming \( E \) this way because it has nice multiplication properties, making it quick to work with. Similarly note the column of \( 1 \)'s in \( S \), that will pick out the bottom row in \( S^{-1} \).
</p>


\begin{align}
S E_{3,3} S^{-1}
&= (S E_{3,3}) S^{-1} \\
&= \begin{pmatrix} 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{pmatrix} S^{-1} \\
&= \begin{pmatrix} \frac{1}{2} & \frac{1}{3} & \frac{1}{6} \\
\frac{1}{2} & \frac{1}{3} & \frac{1}{6} \\
\frac{1}{2} & \frac{1}{3} & \frac{1}{6} \end{pmatrix} \\
\end{align}
</div>
</li>
</ol>
</div>
<div id="outline-container-orgfaf910f" class="outline-4">
<h4 id="orgfaf910f"><span class="section-number-4">1.3.4.</span> Problem 4</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
Consider the Rainbow Warriors Baseball team. They either win or lose a season. There are four possible combinations of their performance during this year and the last. Denote their performance by a two character string, where the first character is the performance last year and the second character is how they performed this year. That is,
</p>

<ul class="org-ul">
<li>\( WW \) if they won the last year and this year</li>
<li>\( WL \) if they won the last year but lost this year</li>
<li>\( LW \) if they lost last year but one this year</li>
<li>\( LL \) if they lost last year and this year</li>
</ul>

<p>
Because the team can either win or lose, we can transition from one state to the next by their performance. Giving us the diagram:
</p>

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm, thin, bend angle = 20] \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
\node[state] (A) {$WW$}; 
\node[state] (B) [right of=A] {$WL$};
\node[state] (C) [below of=A] {$LW$};
\node[state] (D) [below of=B] {$LL$};
\path (A) edge [loop above] node[above] {$W$} (A);
\path (A) edge node[above] {$L$} (B);
\path (B) edge [bend right] node[sloped,above] {$W$} (C);
\path (B) edge node[right] {$L$} (D);
\path (C) edge node[left] {$W$} (A);
\path (C) edge [bend right] node[sloped,below] {$L$} (B);
\path (D) edge node[below] {$W$} (C);
\path (D) edge [loop below] node[below] {$L$} (D);
\end{tikzpicture}

<p>
Using the information from the problem statement we can fill in \( W \) and \( L \) on the arrows with the given probabilities. Note that we are given the probabilities in each state for \( W \) but the total probability leaving the state must be \( 1 \) hence we can infer \( L = 1 - W \).
</p>


\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm, thin, bend angle = 20] \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
\node[state] (A) {$WW$}; 
\node[state] (B) [right of=A] {$WL$};
\node[state] (C) [below of=A] {$LW$};
\node[state] (D) [below of=B] {$LL$};
\path (A) edge [loop above] node[above] {$0.7$} (A);
\path (A) edge node[above] {$0.3$} (B);
\path (B) edge [bend right] node[sloped,above] {$0.4$} (C);
\path (B) edge node[right] {$0.6$} (D);
\path (C) edge node[left] {$0.5$} (A);
\path (C) edge [bend right] node[sloped,below] {$0.5$} (B);
\path (D) edge node[below] {$0.2$} (C);
\path (D) edge [loop below] node[below] {$0.8$} (D);
\end{tikzpicture}

<p>
We were also given standard names for each of the states in the problem.
</p>


\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm, thin, bend angle = 20] \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
\node[state] (A) {$0$}; 
\node[state] (B) [right of=A] {$2$};
\node[state] (C) [below of=A] {$1$};
\node[state] (D) [below of=B] {$3$};
\path (A) edge [loop above] node[above] {$0.7$} (A);
\path (A) edge node[above] {$0.3$} (B);
\path (B) edge [bend right] node[sloped,above] {$0.4$} (C);
\path (B) edge node[right] {$0.6$} (D);
\path (C) edge node[left] {$0.5$} (A);
\path (C) edge [bend right] node[sloped,below] {$0.5$} (B);
\path (D) edge node[below] {$0.2$} (C);
\path (D) edge [loop below] node[below] {$0.8$} (D);
\end{tikzpicture}
</div>
<ol class="org-ol">
<li><a id="org7ec3695"></a>A<br />
<div class="outline-text-5" id="text-1-3-4-1">
<p>
The transition probability matrix is read from the above diagram.
</p>

<p>
\( P = \begin{pmatrix}
0.7 & 0 & 0.3 & 0 \\
0.5 & 0 & 0.5 & 0 \\
0 & 0.4 & 0 & 0.6 \\
0 & 0.2 & 0 & 0.8 \\
\end{pmatrix} \) 
</p>
</div>
</li>
<li><a id="orgcc85d45"></a>B<br />
<div class="outline-text-5" id="text-1-3-4-2">
<p>
The long run proportion \( \pi \) is a row vector satisfying:
\( \pi P = \pi \) this implies \( \pi (P - I) \) so \( \pi \) is an element of the null space of \( (P-I)^T \).
</p>

<p>
This is a standard linear algebra exercise.
The null space has dimension one and is spanned by the vector \( \begin{pmatrix} \frac{5}{9} & \frac{1}{3} & \frac{1}{3} & 1 \end{pmatrix} \). We have an additional constraint that the sum of the elements must add to one (meaning \( \frac{5}{9}c + \frac{1}{3}c + \frac{1}{3}c + 1c = 1 \implies c = \frac{9}{20} \implies \pi = \begin{pmatrix} \frac{1}{4} & \frac{3}{20} & \frac{3}{20} & \frac{9}{20} \end{pmatrix} \))
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgaf89f85" class="outline-4">
<h4 id="orgaf89f85"><span class="section-number-4">1.3.5.</span> Problem 5</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
The transition matrix is \( P = \begin{pmatrix}
0 & 1/2 & 1/2 \\
1/2 & 0 & 1/2 \\
1/2 & 1/2 & 0  \end{pmatrix} = \frac{1}{2} (J - I) \) where \( J = \begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1  \end{pmatrix} \)  is the matrix of ones and \( I \) is the identity matrix.
</p>

<p>
To find the probability that a state returns to itself, we need to find out the element of the diagonal of \( P^{(n)} \).
</p>

<p>
We may leverage symmetry in the problem to reduce computation.
</p>

<p>
Note, the matrix \( P \) is symmetric, hence \( P^n \) is also symmetric. Thus the elements on the diagonal are the same. We may then compute a diagonal element by using \( \tr(P^{n}) / 3 \).
</p>

<p>
Furthermore, the trace can also be computed in two ways. The trace is both the sum of the diagonal elements and the sum of the eigenvalues. In this problem calculating the sum of the eigenvalues is easier.
</p>

<p>
The matrix \( J \) has well known eigenvalues.
\( J \) has eigenvalues \( 2 \) with multiplicity \( 1 \) and \( 0 \) with multiplicity \( 2 \).
</p>

<p>
\( J - I \) then has eigenvalues \( 1 \) with multiplicity \( 1 \) and \( -1 \) with multiplicity \( 2 \).
</p>

<p>
\( P =  \frac{1}{2} (J - I) \) has eigenvalues \( 1 \) with multiplicity \( 1 \) and \( \frac{-1}{2} \) with multiplicity \( 2 \).
</p>

<p>
Hence, the eigenvalues of \( P^n \) is then \( 1 \) with multiplicity \( 1 \) and \( \left( \frac{-1}{2} \right)^n \) with multiplicity \( 2 \). 
</p>

<p>
Thus, \( \tr(P^n) = 1 + 2(\frac{-1}{2})^n \)
</p>

<p>
Hence the probability that the element returns to itself is \( \frac{1 + 2(\frac{-1}{2})^n}{3} \) 
</p>
</div>
</div>
</div>
<div id="outline-container-org93771dd" class="outline-3">
<h3 id="org93771dd"><span class="section-number-3">1.4.</span> Homework 4</h3>
<div class="outline-text-3" id="text-1-4">
</div>
<div id="outline-container-org661e144" class="outline-4">
<h4 id="org661e144"><span class="section-number-4">1.4.1.</span> Problem 1</h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
Consider a birth and death process with birth rates \( \{ \lambda_i \}_{i \geq 0}   \) and death rates \( \{ \mu_i \}_{i \geq 1} \). Let \( T_i \) be the time the process takes for the population size to go from \( i \) to \( i + 1 \).
</p>
</div>
<ol class="org-ol">
<li><a id="org2c844bd"></a>A<br />
<div class="outline-text-5" id="text-1-4-1-1">
<p>
The random variable \( T_i \) may transition from state \( i \) to \( i + 1 \) (birth) or \( i - 1 \) (death). Let us denote the first transition from state \( i \) by a random variable \( I_i \). That is,
</p>

<p>
\[ I_i = \begin{cases} 1 & \text{If the first transistion from state $i$ is a birth} \\ 0 & \text{If the first transistion from state $i$ is a death} \end{cases} \]
</p>

<p>
We may consider the conditional expectation \( \mathbb{E}[T_i \vert I_i] \).
Regardless of whether the transistion is a birth or a death, the time it takes for the process \( T_i \) to transition at all is exponential with rate \( \lambda_i + \mu_i \) (mean \(\frac{1}{\lambda_i + \mu_i}\)). If the first transition is a birth, then we do not need to wait any longer to go from \( i \) to \( i + 1 \). This means,
</p>

<p>
\[ \mathbb{E}[T_i \vert I_i = 1] = \frac{1}{\lambda_i + \mu_i} \]
</p>

<p>
If the first transition is a death, then from state \( i - 1 \) it will take the expected amount of time to go to state \( i \) first (\( \mathbb{E}[T_{i - 1}] \)), then to state \( i + 1 \) (\( \mathbb{E}[T_{i}] \)). This means,
</p>


<p>
\[ \mathbb{E}[T_i \vert I_i = 0] = \frac{1}{\lambda_i + \mu_i} + \mathbb{E}[T_{i - 1}] + \mathbb{E}[T_i]\]
</p>

<p>
By the law of total expectation, we may bring this together.
</p>

<p>
\[ \mathbb{E}[T_i \vert I_i] = \mathbb{E}[T_i \vert I_i = 1] \mathbb{P}(I_i = 1) + \mathbb{E}[T_i \vert I_i = 0] \mathbb{P}(I_i = 0) \]
</p>

<p>
Substituting the probabilities and conditional expectations, yields
</p>


<p>
\[ \mathbb{E}[T_i] =  \frac{1}{\lambda_i + \mu_i} \cdot \left(\frac{\lambda_i}{\lambda_i + \mu_i} \right) + \left(\frac{1}{\lambda_i + \mu_i} + \mathbb{E}[T_{i - 1}] + \mathbb{E}[T_i]\right) \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \]
</p>

<p>
We may simplify more using the substitution
</p>

<p>
\[ \frac{\lambda_i}{\lambda_i + \mu_i} = 1 - \frac{\mu_i}{\lambda_i + \mu_i} \]
</p>

<p>
Hence
\[ \mathbb{E}[T_i] =  \frac{1}{\lambda_i + \mu_i} \cdot \left(1 - \frac{\mu_i}{\lambda_i + \mu_i} \right) + \left(\frac{1}{\lambda_i + \mu_i} + \mathbb{E}[T_{i - 1}] + \mathbb{E}[T_i]\right) \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \]
</p>

<p>
The rest are algebraic manipulations,
</p>
\begin{align*}
\mathbb{E}[T_i]
&=  \frac{1}{\lambda_i + \mu_i} \cdot \left(1 - \frac{\mu_i}{\lambda_i + \mu_i} \right) + \left(\frac{1}{\lambda_i + \mu_i} + \mathbb{E}[T_{i - 1}] + \mathbb{E}[T_i]\right) \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \\
&=  \frac{1}{\lambda_i + \mu_i}  - \frac{\mu_i}{(\lambda_i + \mu_i)^2} + \frac{\mu}{(\lambda_i + \mu_i)^2} + \mathbb{E}[T_{i - 1}] \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) + \mathbb{E}[T_i] \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \\
&=  \frac{1}{\lambda_i + \mu_i} + \mathbb{E}[T_{i - 1}] \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) + \mathbb{E}[T_i] \cdot \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \\
&=  \frac{1}{\lambda_i + \mu_i} + \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \cdot (\mathbb{E}[T_{i - 1}]  + \mathbb{E}[T_i])
\end{align*}

<p>
Now, by subtracting \( \mathbb{E}[T_i] \) on both sides we get
</p>

<p>
\[ 0 = \frac{1}{\lambda_i + \mu_i} + \left(\frac{\mu_i}{\lambda_i + \mu_i} \right) \cdot (\mathbb{E}[T_{i - 1}]  + \mathbb{E}[T_i]) - \mathbb{E}[T_i] \]
</p>

<p>
Multiplying by \( \lambda_i + \mu_i \) yields
\[ 0 = 1 + \mu_i \mathbb{E}[T_{i - 1}]  + \mu_i \mathbb{E}[T_i] - (\lambda_i + \mu_i) \mathbb{E}[T_i] \]
</p>

<p>
Cancelling common terms yields
\[ 0 = 1 + \mu_i \mathbb{E}[T_{i - 1}] - \lambda_i \mathbb{E}[T_i] \]
</p>

<p>
Moving \( \mathbb{E}[T_i] \) terms to one side and isolating yields
\[ \lambda_i \mathbb{E}[T_i] = 1 + \mu_i \mathbb{E}[T_{i - 1}]  \]
\[ \mathbb{E}[T_i] = \frac{1}{\lambda_i} + \frac{\mu_i}{\lambda_i} \mathbb{E}[T_{i - 1}]  \]
</p>

<p>
Which is our final answer.
</p>
</div>
</li>
<li><a id="orgf68e848"></a>B<br />
<div class="outline-text-5" id="text-1-4-1-2">
<p>
Suppose the birth and death process have constant paramters \( \lambda_i = \lambda \) and \( \mu_i = \mu \). Calculate \( \mathbb{E}[T_{kj}] \), the expected value of the time to go from state \( k \) to state \( j \).
</p>

<p>
Given the base case \( \mathbb{E}[T_0] = \frac{1}{\lambda} \)  and recurrence relation \( \mathbb{E}[T_i] = \frac{1}{\lambda_i} + \frac{\mu_i}{\lambda_i} \mathbb{E}[T_{i - 1}]  \) from part A, we may calculate \( \mathbb{E}[T_i] \) explicitly by induction.
</p>

<p>
We may show that if \( \lambda \neq \mu \) then the expected value is
\[ \mathbb{E}[T_i] = \frac{1 - \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\lambda - \mu} \]
</p>

<ul class="org-ul">
<li>Base Case</li>
</ul>

<p>
\[ \mathbb{E}[T_0] = \frac{1 - \left( \frac{\mu}{\lambda} \right)^{1}}{\lambda - \mu} = \frac{\lambda - \mu}{(\lambda - \mu) \lambda} = \frac{1}{\lambda} \] 
</p>

<ul class="org-ul">
<li>Inductive Step</li>
</ul>

<p>
Suppose for \( i \in \mathbb{N} \) the following holds
\[ \mathbb{E}[T_i] = \frac{1 - \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\lambda - \mu} \]
Consider \( i + 1 \)
</p>
\begin{align*}
\mathbb{E}[T_{i + 1}]
&= \frac{1}{\lambda} + \frac{\mu}{\lambda} \mathbb{E}[T_{i}] \\
&=  \frac{1}{\lambda} + \frac{\mu}{\lambda} \cdot \frac{1 - \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\lambda - \mu} \\
&=  \frac{\lambda - \mu}{\lambda (\lambda - \mu)} +  \frac{\mu - \mu \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\lambda (\lambda - \mu)} \\
&=  \frac{\lambda - \mu \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\lambda (\lambda - \mu)} \\
&=  \frac{\left( \frac{1}{\lambda} \right) \lambda - \mu \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\left( \frac{1}{\lambda} \right) \lambda (\lambda - \mu)} \\
&=  \frac{1 - \frac{\mu}{\lambda} \left( \frac{\mu}{\lambda} \right)^{i + 1}}{(\lambda - \mu)} \\
&=  \frac{1 -  \left( \frac{\mu}{\lambda} \right)^{i + 2}}{(\lambda - \mu)}
\end{align*}

<p>
We may use this formula to find \( \mathbb{E}[T_{kj}] \). Note that to get from state \( k \) to \( j \) we will first need to get through states \( k + 1, k + 2, \cdots, j - 2, j - 1, j \). That is, \( T_{j - 1} = \sum_{i = k}^{j - 1} T_{i} \). We may use the linearity of expectation to note that \( \mathbb{E}[T_{kj}] = \sum_{i = k}^{j - 1} \mathbb{E}[T_i]  \)
</p>

<p>
Then, using summation rules (pulling out constants, sum of \( 1 \)'s is difference of indicies \( +1 \)).
</p>

<p>
\[ \sum_{i = k}^{j - 1} \mathbb{E}[T_i] = \sum_{i = k}^{j - 1} \frac{1 - \left( \frac{\mu}{\lambda} \right)^{i + 1}}{\lambda - \mu}  = \frac{1}{\lambda - \mu} \cdot \sum_{i = k}^{j - 1} 1 - \left( \frac{\mu}{\lambda} \right)^{i + 1} = \frac{1}{\lambda - \mu} \cdot \left( (j - k) - \sum_{i = k}^{j - 1} \left( \frac{\mu}{\lambda} \right)^{i + 1} \right) \]
</p>

<p>
Lastly we shall notice that the last equality holds a geometric sum with ratio \( \frac{\mu}{\lambda} \). This has a well known closed form. Substituting yields:
\[ \sum_{i = k}^{j - 1} \left( \frac{\mu}{\lambda} \right)^{i + 1} \right) =  \]
</p>


\begin{align*}
\frac{1}{\lambda - \mu} \cdot \left( (j - k) - \sum_{i = k}^{j - 1} \left( \frac{\mu}{\lambda} \right)^{i + 1} \right)
&= \frac{1}{\lambda - \mu} \cdot \left( (j - k) - \left( \frac{-\left(\frac{\mu}{\lambda} \right)^{j + 1} + \left( \frac{\mu}{\lambda} \right)^{k + 1}}{1 - \frac{\mu}{\lambda}} \right) \right) \\
&= \frac{1}{\lambda - \mu} \cdot \left( (j - k) - \left( \frac{\mu}{\lambda} \right)^{k + 1} \left( \frac{- \left( \frac{\mu}{\lambda} \right)^{j - k} + 1}{1 - \frac{\mu}{\lambda}} \right) \right) \\
&=  \frac{(j - k)}{\lambda - \mu} - \frac{\left( \frac{\mu}{\lambda} \right)^{k + 1}}{\lambda - \mu} \left( \frac{-\left( \frac{\mu}{\lambda} \right)^{j - k} + 1}{1 - \frac{\mu}{\lambda}} \right)  \\
\end{align*}

<p>
Which is our desired result.
</p>

<p>
If \( \lambda = \mu \) then we use the same defining recurrence relation, \( \mathbb{E}[T_i] = \frac{1}{\lambda_i} + \frac{\mu_i}{\lambda_i} \mathbb{E}[T_{i - 1}]  \) from part A. This ends up being simpler in this case, \( \mathbb{E}[T_i] = \frac{1}{\lambda} + \mathbb{E}[T_{i - 1}]  \). We may calculate \( \mathbb{E}[T_i] \) explicitly by induction. We may show each expected value is of the form \( \mathbb{E}[T_i] = \frac{i + 1}{\lambda} \).
</p>

<ul class="org-ul">
<li>Base Case
\[ \mathbb{E}[T_0] = \frac{0 + 1}{\lambda} = \frac{1}{\lambda} \]</li>

<li>Inductive Step</li>
</ul>

<p>
Suppose for some \( i \in \mathbb{N} \) we have \( \mathbb{E}[T_i] = \frac{i + 1}{\lambda} \).
</p>

<p>
Then \[ \mathbb{E}[T_{i + 1}] = \frac{1}{\lambda} + \mathbb{E}[T_i] = \frac{1}{\lambda} + \frac{i+1}{\lambda} = \frac{(i + 1) + 1}{\lambda} \].
</p>

<p>
By similar reasoning the expected value can be represented as the sum of times between \( k \) and \( j \),
</p>

\begin{align*}
\sum_{i = k}^{j - 1} \mathbb{E}[T_i]
&= \sum_{i = k}^{j - 1} \frac{i + 1}{\lambda} \\
&= \frac{j-k}{\lambda}  + \frac{1}{\lambda} \sum_{i = k}^{j - 1} i  \\
&= \frac{j-k}{\lambda}  + \frac{1}{\lambda} \frac{(j - 1 + k)(j - k)}{2}  \\
&= \frac{2j-2k}{2 \lambda}  + \frac{(j - 1 + k)(j - k)}{2 \lambda}  \\
&= \frac{2j-2k + j^2 - jk - j + k + jk - k^2}{2 \lambda}  \\
&= \frac{j-k + j^2- k^2}{2 \lambda}  \\
&= \frac{j(j + 1)- k(k + 1)}{2 \lambda}  \\
\end{align*}

<p>
Which is the desired result.
</p>
</div>
</li>
<li><a id="org5f2bac9"></a>C<br />
<div class="outline-text-5" id="text-1-4-1-3">
<p>
Similar to how we conditioned on \( I_i \) in part A to find the expected value, we would like to condition on \( I_i \) to find the variance. We would like to use the following law of total variance,
</p>

<p>
\[ \mathbb{V}[T_i] = \mathbb{V}[\mathbb{E}[T_i \vert I_i]] + \mathbb{E}[\mathbb{V}[T_i \vert I_i]] \]
</p>

<p>
We start with the first term. From part A, we have that
</p>

<p>
\[ \mathbb{E}[T_i \vert I_i] = \begin{cases} \frac{1}{\lambda_i + \mu_i} & I_i = 1 \\ \frac{1}{\lambda_i + \mu_i} + \mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}] & I_i = 0 \end{cases} \]
</p>

<p>
We may "package" this piecewise function using the indicator function.
</p>


<p>
\[ \mathbb{E}[T_i \vert I_i] =  \frac{1}{\lambda_i + \mu_i} + (1 - I_i)(\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}]) \]
</p>

<p>
Now it is easy to take the variance of such a formula. Note that \( I_i \) is Bernoulli with parameter \( \frac{\lambda_i}{\lambda_i + \mu_i} \).
</p>

\begin{align*}
\mathbb{V}[\mathbb{E}[T_i \vert I_i]]
&= \mathbb{V}\left[ \frac{1}{\lambda_i + \mu_i} + (1 - I_i)(\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}]) \right] \\
&= \mathbb{V}\left[ (1 - I_i)(\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}]) \right] \\
&= (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2\mathbb{V}\left[ 1 - I_i \right] \\
&= (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2\mathbb{V}\left[ I_i \right] \\
&= (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2 \frac{\lambda_i \mu_i}{(\lambda_i + \mu_i)^2} \\
\end{align*}

<p>
Now, for the second term. In order to take the expected value we need a formula for the variance that looks like the following
</p>


<p>
\[ \mathbb{V}[T_i \vert I_i] = \begin{cases} ? & I_i = 1 \\ ? & I_i = 0 \end{cases} \]
</p>


<p>
If we consider when a birth occurs \( I_i = 1 \), then this is the variance of the waiting time for a transistion to happen. This is the variance of an exponential random variable with rate \( \lambda_i + \mu_i \). Hence \( \mathbb{V}[T_i \vert I_i = 1] = \frac{1}{(\lambda_i + \mu_i)^2} \). If we consider when a death occurs, we first need to wait for the death to occur then we would need to wait to return back to the state \( i \) then to \( i+1 \). This the total variance is \( \mathbb{V}[T_i \vert I_i = 1] = \frac{1}{(\lambda_i + \mu_i)^2} + \mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}] \). We now have the proper form of the variance.
</p>

<p>
\[ \mathbb{V}[T_i \vert I_i] = \begin{cases} \frac{1}{(\lambda_i + \mu_i)^2} & I_i = 1 \\ \frac{1}{(\lambda_i + \mu_i)^2} + \mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}] & I_i = 0 \end{cases} \]
</p>

<p>
With this form we may again "package" the information using the indicator random variable.
</p>

<p>
\[ \mathbb{V}[T_i \vert I_i] = \frac{1}{(\lambda_i + \mu_i)^2} + (1 - I_i) (\mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}]) \]
</p>

<p>
This form is easiest to take the expectation of.
</p>

\begin{align*}
\mathbb{E}[\mathbb{V}[T_i \vert I_i]]
&= \mathbb{E}[\frac{1}{(\lambda_i + \mu_i)^2} + (1 - I_i) (\mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}])] \\
&= \frac{1}{(\lambda_i + \mu_i)^2} + \mathbb{E}[(1 - I_i) (\mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}])] \\
&= \frac{1}{(\lambda_i + \mu_i)^2} + (\mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}]) \mathbb{E}[(1 - I_i) ] \\
&= \frac{1}{(\lambda_i + \mu_i)^2} + (\mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}]) \left(\frac{\mu_i}{\lambda_i + \mu_i}\right)
\end{align*}

<p>
By the law of total variance this becomes
\[ \mathbb{V}[T_{i}] = (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2 \frac{\lambda_i \mu_i}{(\lambda_i + \mu_i)^2} + \frac{1}{(\lambda_i + \mu_i)^2} + (\mathbb{V}[T_{i-1}] + \mathbb{V}[T_{i}]) \left(\frac{\mu_i}{\lambda_i + \mu_i}\right) \]
Distributing the coeficient on the variences yields,
</p>

<p>
\[ \mathbb{V}[T_{i}] = (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2 \frac{\lambda_i \mu_i}{(\lambda_i + \mu_i)^2} + \frac{1}{(\lambda_i + \mu_i)^2} + \mathbb{V}[T_{i-1}] \left(\frac{\mu_i}{\lambda_i + \mu_i}\right) + \mathbb{V}[T_{i}] \left(\frac{\mu_i}{\lambda_i + \mu_i}\right) \]
Grouping \( \mathbb{V}[T_i] \) terms
\[ (1 - \frac{\mu_i}{\lambda_i + \mu_i})\mathbb{V}[T_{i}] = (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2 \frac{\lambda_i \mu_i}{(\lambda_i + \mu_i)^2} + \frac{1}{(\lambda_i + \mu_i)^2} + \mathbb{V}[T_{i-1}] \left(\frac{\mu_i}{\lambda_i + \mu_i}\right) \]
\[ (\frac{\lambda_i}{\lambda_i + \mu_i})\mathbb{V}[T_{i}] = (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2 \frac{\lambda_i \mu_i}{(\lambda_i + \mu_i)^2} + \frac{1}{(\lambda_i + \mu_i)^2} + \mathbb{V}[T_{i-1}] \left(\frac{\mu_i}{\lambda_i + \mu_i}\right) \]
\[ \mathbb{V}[T_{i}] = (\mathbb{E}[T_{i - 1}] + \mathbb{E}[T_{i}])^2 \frac{ \mu_i}{(\lambda_i + \mu_i)} + \frac{1}{(\lambda_i + \mu_i) \lambda_i} + \mathbb{V}[T_{i-1}] \left(\frac{\mu_i}{\lambda_i}\right){ \]
</p>

<p>
This is the desired result.
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-org7aa4a3a" class="outline-4">
<h4 id="org7aa4a3a"><span class="section-number-4">1.4.2.</span> Problem 2</h4>
<div class="outline-text-4" id="text-1-4-2">
</div>
<ol class="org-ol">
<li><a id="orgf51f2c0"></a>A<br />
<div class="outline-text-5" id="text-1-4-2-1">
<p>
Consider a two state, \( \{0,1\} \), continuous time Markov chain, \( P(t) \), with matrix,
</p>

<p>
\[ Q = \begin{pmatrix} - \lambda & \lambda \\ \mu & -\mu \end{pmatrix}\]
</p>

<p>
Such that \( P'(t) = Q P(t) = P(t) Q \) 
</p>

<p>
By hypothesis of the Markov chain, we have the relation on \( P(t) \)
\[ P_{00}(t) + P_{01}(t) = P_{10}(t) + P_{11}(t) = 1 \].
From this, it is enough to solve for the first column of \( P(t) \) as the second column has elements \( 1 -  \text{First Col} \).
</p>
</div>
<ol class="org-ol">
<li><a id="org4726893"></a>Forward Equation<br />
<div class="outline-text-6" id="text-1-4-2-1-1">
<p>
The first column of the forwards equation \( P'(t) = P(t) Q \) is
</p>

\begin{align*}
P_{00}'(t) &= - \lambda P_{00}(t) + \mu P_{01}(t) \\
P_{10}'(t) &= - \lambda P_{10}(t) + \mu P_{11}(t) \\
\end{align*}

<p>
Both equations have two unknowns from the same row. We may use the relation that \( P_{r1} = 1 - P_{r0} \) to simplify.
</p>

\begin{align*}
P_{00}'(t) &= - \lambda P_{00}(t) + \mu (1 - P_{00}(t)) = \mu - (\lambda + \mu)P_{00}(t) \\
P_{10}'(t) &= - \lambda P_{10}(t) + \mu (1 - P_{10}(t)) = \mu - (\lambda + \mu)P_{10}(t) \\
\end{align*}

<p>
These are both first order linear ordinary differential equations with constant coefficients. They have solutions. 
</p>
\begin{align*}
P_{00}(t) &= \frac{\mu}{\lambda + \mu} + c_1 e^{-(\lambda + \mu)t} \\
P_{10}(t) &= \frac{\mu}{\lambda + \mu} + c_1 e^{-(\lambda + \mu)t}
\end{align*}

<p>
Using the initial condition that \( P_{00}(0) = 1 \) and \( P_{10}(0) = 0 \) we obtain the solution
</p>

\begin{align*}
P_{00}(t) &= \frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} \\
P_{00}(t) &= \frac{\mu}{\lambda + \mu} - \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t}
\end{align*}

<p>
From this solution we can obtain \( P_{01} \) from the relation \( P_{01} = 1 - P_{00} \) and \( P_{11} \) from \( P_{11} = 1 - P_{10} \). Putting these all in a matrix yields.
</p>

<p>
\[ P(t) =
\begin{pmatrix}
\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} &
1 - (\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t}) \\
\frac{\mu}{\lambda + \mu} - \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t} &
1 - (\frac{\mu}{\lambda + \mu} - \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t})
\end{pmatrix} \]
</p>

<p>
We may simplify using \( 1  - \frac{\mu}{\mu + \lambda} = \frac{\lambda}{\mu + \lambda} \)
</p>

<p>
\[ P(t) =
\begin{pmatrix}
\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} &
\frac{\lambda}{\lambda + \mu} - \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} \\
\frac{\mu}{\lambda + \mu} - \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t} &
\frac{\lambda}{\lambda + \mu} + \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t} &
\end{pmatrix} \]
</p>
</div>
</li>
<li><a id="org8c36229"></a>Backward Equation<br />
<div class="outline-text-6" id="text-1-4-2-1-2">
<p>
The first column of the backwards equation \( P'(t) = Q P(t) \) is
</p>

\begin{align*}
P_{00}'(t) &= \lambda P_{10}(t) - \lambda P_{00}(t) \\
P_{10}'(t) &= \mu P_{00}(t) - \mu P_{10}(t) \\
\end{align*}

<p>
Notice, that
</p>
\begin{align*}
\mu P_{00}'(t) &= \mu \lambda P_{10}(t) - \mu \lambda P_{00}(t) \\
\lambda P_{10}'(t) &= \lambda \mu P_{00}(t) - \lambda \mu P_{10}(t) \\
\end{align*}

<p>
So \( \mu P_{00}'(t) + \lambda P_{10}'(t) = 0 \implies \mu P_{00}(t) + \lambda P_{10}(t) = c \).
</p>

<p>
We also have that \( P(0) = I \) which implies that \( \mu = c \). Let us isolate \( P_{10} \) in order to construct a differential equation of one unknown.
</p>

<p>
\[\mu P_{00}(t) + \lambda P_{10}(t) = \mu \implies  \lambda P_{10}(t) = \mu - \mu P_{00}(t) \]
</p>

<p>
Hence \( P_{00}'(t) &= \lambda (\mu - \mu P_{00}(t)) - \lambda P_{00}(t) \)
</p>

<p>
The differential equation is a first order linear ordinary differential equation with constant coefficients
</p>

<p>
\( P_{00}'(t) &= \mu - (\lambda + \mu) P_{00}(t) \)
</p>

<p>
This has solution
</p>

<p>
\[ P_{00}(t) = \frac{\mu}{\lambda + \mu} + c_1 e^{-(\lambda + \mu)t} \]
</p>

<p>
Usin the initial condition that \( P_{00}(0) = 1 \) we obtain the solution
</p>

<p>
\[ P_{00}(t) = \frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} \]
</p>

<p>
From this solution we can obtain \( P_{01} \) from the relation \( P_{01} = 1 - P_{00} \). We may also obtain \( P_{10} = \frac{1}{\lambda} (\mu - \mu P_{00}) \). We may then obtain \( P_{11} \) from \( P_{11} = 1 - P_{10} \). Putting these all in a matrix yields.
</p>

<p>
\[ P(t) =
\begin{pmatrix}
\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} &
1 - (\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t}) \\
(\frac{\mu}{\lambda})(1 - (\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t})) &
1 - (\frac{\mu}{\lambda})(1 - \frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t})
\end{pmatrix} \]
</p>

<p>
We may simplify using \( 1  - \frac{\mu}{\mu + \lambda} = \frac{\lambda}{\mu + \lambda} \)
</p>

<p>
\[ P(t) =
\begin{pmatrix}
\frac{\mu}{\lambda + \mu} + \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} &
\frac{\lambda}{\lambda + \mu} - \frac{\lambda}{\lambda + \mu} e^{-(\lambda + \mu)t} \\
\frac{\mu}{\lambda + \mu} - \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t} &
\frac{\lambda}{\lambda + \mu} + \frac{\mu}{\lambda + \mu} e^{-(\lambda + \mu)t} &
\end{pmatrix} \]
</p>
</div>
</li>
</ol>
</li>
<li><a id="org5e8d8ba"></a>B<br />
<div class="outline-text-5" id="text-1-4-2-2">
<p>
Using the solution above for \( P(t) \) we may compute the limit (each element has \( e^{-(\lambda + \mu)t} \) term which goes to \( 0 \) as \( t \to \infty \))
</p>

<p>
\[ \lim_{t \to \infty} P(t) =
\begin{pmatrix}
\frac{\mu}{\lambda + \mu}  &
\frac{\lambda}{\lambda + \mu}  \\
\frac{\mu}{\lambda + \mu}  &
\frac{\lambda}{\lambda + \mu} 
\end{pmatrix} \]
</p>

<p>
This immediately tells us the probability that the Markov chain will be in state zero is \( \frac{\mu}{\lambda + \mu} \).
</p>

<p>
However, a more rigorous way to show this fact is to solve the two equations \( \pi Q = 0 \) and \( \sum_i \pi_i = 1 \). The former equation comes from the defining equation for \( \pi \)
</p>

<p>
\[ \pi P(t) = \pi \implies \pi P'(t) = 0 \implies \pi Q P(t) = 0 \]
We know that the solution to \( P(t) \) is \( e^{Qt} \) and one property of the matrix exponential is \( \det(e^{Qt}) = e^{\text{tr}(Qt)} \). So as long as \( \lambda + \mu \neq 0 \) then \( P(t) \) is invertible. Thus we have that \( \pi Q = 0 \).
</p>

<p>
Hence,
</p>

<p>
\[ \pi Q = \begin{pmatrix} -\lambda \pi_0 + \mu \pi_1 & \lambda \pi_0 + -\mu \pi_1 \end{pmatrix} = \begin{pmatrix} 0 & 0 \end{pmatrix} \]
</p>

<p>
Also, \[\pi_0 + \pi_1 = 1 \implies \pi_1 = 1 - \pi_0\]
</p>

<p>
Thus, \( 0 = - \lambda \pi_0 + \mu (1 - \pi_0) \implies \pi_0 =  \frac{\mu}{\lambda + \mu} \).
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orgaf76a09" class="outline-4">
<h4 id="orgaf76a09"><span class="section-number-4">1.4.3.</span> Problem 3</h4>
<div class="outline-text-4" id="text-1-4-3">
<p>
We are asked to approximate the probability
</p>

<p>
\[ \mathbb{P}(N(3) \leq 230) \]
</p>

<p>
Using theorem 3.3.5 in the book. We may approximate the probability if we know \( \mu \) and \( \sigma \).
</p>

<p>
First, we may calculate the expected value
</p>

\begin{align*}
\mathbb{E}[X_n]
&= \int_0^{\infty} x \cdot \frac{2 \sqrt{2}}{\pi(x^4 + 1)} dx \\
&= \int_0^{\infty}  \frac{\sqrt{2}}{\pi(u^2 + 1)} du \\
&= \left. \frac{\sqrt{2} \tan^{-1}(u)}{\pi} \right\vert_{0}^{\infty} \\
&= \frac{\sqrt{2}}{\pi} \frac{\pi}{2} \\
&= \frac{1}{\sqrt{2}}
\end{align*}

<p>
Next the variance, we need to know the second moment of \( X_n \).
</p>

\begin{align*}
\mathbb{E}[X_n^2]
&= \int_0^{\infty} x^2 \cdot \frac{2 \sqrt{2}}{\pi(x^4 + 1)} dx \\
&= 1
\end{align*}
<p>
I asked WolframAlpha for help on this one. 
</p>

<p>
The variance is then
</p>

<p>
\[ \mathbb{V}(X_n) = \mathbb{E}[X_n^2] - \mathbb{E}[X_n]^2 = 1 - \left(\frac{1}{\sqrt{2}}\right)^2 = \frac{1}{2} \]
</p>

<p>
We may now calculate the probability,
</p>

<p>
\[ \mathbb{P}(N(t) \geq 230) = \mathbb{P}\left(\frac{N(t) - t \sqrt{2}}{\sqrt{t \cdot \frac{1}{2} \cdot 2^{3/2}}} \geq \frac{230 - t \sqrt{2}}{\sqrt{t \cdot \frac{1}{2} \cdot 2^{3/2}}} \right) \]
</p>

<p>
When \( t = 3 \) (my first interpretation, \( t \) is in years here) the value is incredibly small, near \( 0 \). Perhaps that was the punchline, but I may have also mis-interpreted the units. Suppose \( t \) were calculated in days. Then \( t = 1095 \) and the probability is very high, near \( 1 \). Suppose \( t \) were calculated in weeks. Then \( t = 156 \) and the probability is reasonable, near \( 0.26 \).
</p>
</div>
</div>
<div id="outline-container-orgddfbf81" class="outline-4">
<h4 id="orgddfbf81"><span class="section-number-4">1.4.4.</span> Problem 4</h4>
<div class="outline-text-4" id="text-1-4-4">
<p>
Consider the car buying model. Suppose the lifetime of a car (in years) is uniformly distributed over \( (0,10) \) and suppose that \( C_1 = 3 \) and \( C_2 = 0.5 \).
</p>

<p>
We have that the long run average cost is
</p>

<p>
\[ \frac{C_1 + C_2 H(T)}{\int_0^T x h(x) dx + T(1 - H(T)))} \]
</p>

<p>
Plugging in what's known yields a function of \( T \).
</p>

<p>
\[ \frac{3 + \frac{1}{2} \frac{T}{10}}{\int_0^T x \frac{1}{10} dx + T(1 - \frac{T}{10})} = \frac{60 + T}{20T - T^2} = f(T) \]
</p>

<p>
We may minimize this function by differentiating and setting to zero.
</p>

<p>
\[ f'(T) = \frac{(20T - T^2) - (60+T)(20-2T)}{(20T-T^2)^2} = 0 \]
</p>

<p>
Note that \( T \in (0,10) \) (namely it is not \( 0 \) or \( 20 \)) hence the denominator is never \( 0 \) hence we may multiply to get the relation.
</p>

<p>
\[ T^2 + 120T - 1200 = 0 \]
</p>

<p>
Which has solutions,
</p>

<p>
\[ T = -20(3 + 2 \sqrt{3}), 40 \sqrt{3} - 60 \]
</p>

<p>
Only the later solution \( T = 40 \sqrt{3} - 60  \) is in a valid domain (between \(0\) and \(10\)).
</p>
</div>
</div>
</div>
<div id="outline-container-org45a0254" class="outline-3">
<h3 id="org45a0254"><span class="section-number-3">1.5.</span> Final Presentation - Markov Chain Monte Carlo</h3>
<div class="outline-text-3" id="text-1-5">
</div>
<div id="outline-container-org0ebe652" class="outline-4">
<h4 id="org0ebe652"><span class="section-number-4">1.5.1.</span> The Context</h4>
<div class="outline-text-4" id="text-1-5-1">
<p>
Markov Chain Monte Carlo (MCMC) methods form a powerful framework for handling complicated probability distributions that often arrise in practice. From quantum mechanics to combinatorial optimization, one is hard pressed to find a discipline that does not take advantage of MCMC. Monte Carlo methods are those that use random numbers in order to "brute force" a solution numerically. Markov Chain Monte Carlo is a subset of Monte Carlo that uses a Markov Chain as the source of the randomness for the main Monte Carlo method. This gives rise to a class of algorithms that can be "picky" or "smart" about the types of elements to generate rather than some uniform distribution which have no relation.
In this paper we will present the Metropolis Hastings algorithm; the first MCMC method which creates a method of generating samples from a target probability distribution. The algorithm is simple and elegant. Though this, by no means, entails that the problems it solves are simple.
</p>
</div>
</div>
<div id="outline-container-org4ef92aa" class="outline-4">
<h4 id="org4ef92aa"><span class="section-number-4">1.5.2.</span> Problem Statement</h4>
<div class="outline-text-4" id="text-1-5-2">
<p>
Given a target distribution \( P(x) \) and but we only know a function \( f(x) = k P(x) \). Is it possible to sample from \( P(x) \)? The solution? It is. We will construct a Markov Chain such that its stationary distribution \( \pi_x = P(x) \)
</p>
</div>
</div>
<div id="outline-container-org9b3cf4a" class="outline-4">
<h4 id="org9b3cf4a"><span class="section-number-4">1.5.3.</span> Algorithm</h4>
<div class="outline-text-4" id="text-1-5-3">
<p>
Select an initial value for \( x \), call it \( x_0 \).
</p>

<p>
Then for a large number of iterations, \( i = 1, \cdots, m \) repeat the following
</p>

<p>
Draw a candidate from a proposal distribution \( x^* \sim q( x^* \vert x) \)
</p>

<p>
Calculate an acceptance ratio \( \alpha = \frac{f(x^*)}{f(x)} \frac{q(x \vert x^*)}{q(x^* \vert x)} \)
</p>

<p>
Then generate a random number uniformly in \( [0,1] \) call it \( u \).
</p>

<p>
If \( u \leq \alpha \) then accept the new choice of \( x^* \). Meaning \( x_i = x^* \).
</p>

<p>
If \( u > \alpha \) then reject the new choice of \( x^* \). Meaning \( x_i = x \).
</p>
</div>
</div>
<div id="outline-container-orgff82374" class="outline-4">
<h4 id="orgff82374"><span class="section-number-4">1.5.4.</span> Implementation</h4>
<div class="outline-text-4" id="text-1-5-4">
<p>
Tested on \[ f(x) = e^{\frac{-x^2}{2}} \]
</p>

<div class="org-src-container">
<pre class="src src-python3"><span style="color: #531ab6;">import</span> numpy <span style="color: #531ab6;">as</span> np
<span style="color: #531ab6;">import</span> random
<span style="color: #531ab6;">import</span> matplotlib.pyplot <span style="color: #531ab6;">as</span> plt
<span style="color: #531ab6;">from</span> scipy.stats <span style="color: #531ab6;">import</span> norm
plt.<span style="color: #005e8b;">rcParams</span><span style="color: #000000;">[</span><span style="color: #3548cf;">'figure.figsize'</span><span style="color: #000000;">]</span> = <span style="color: #000000;">[</span>12, 8<span style="color: #000000;">]</span>

<span style="color: #531ab6;">def</span> <span style="color: #721045;">mcmc</span><span style="color: #000000;">(</span>n, f<span style="color: #000000;">)</span>:
    <span style="color: #005e8b;">x</span> = <span style="color: #000000;">[</span>random.random<span style="color: #dd22dd;">()</span><span style="color: #000000;">]</span>
    <span style="color: #531ab6;">for</span> i <span style="color: #531ab6;">in</span> <span style="color: #8f0075;">range</span><span style="color: #000000;">(</span>n<span style="color: #000000;">)</span>:
        <span style="color: #005e8b;">candidate</span> = x<span style="color: #000000;">[</span>i<span style="color: #000000;">]</span> + random.gauss<span style="color: #000000;">(</span>0, 3<span style="color: #000000;">)</span>
        <span style="color: #005e8b;">acceptance_ratio</span> = f<span style="color: #000000;">(</span>candidate<span style="color: #000000;">)</span> / f<span style="color: #000000;">(</span>x<span style="color: #dd22dd;">[</span>i<span style="color: #dd22dd;">]</span><span style="color: #000000;">)</span>

        <span style="color: #531ab6;">if</span> random.random<span style="color: #000000;">()</span> &lt;= acceptance_ratio:
            x.append<span style="color: #000000;">(</span>candidate<span style="color: #000000;">)</span>
        <span style="color: #531ab6;">else</span>:
            x.append<span style="color: #000000;">(</span>x<span style="color: #dd22dd;">[</span>i<span style="color: #dd22dd;">]</span><span style="color: #000000;">)</span>
    <span style="color: #531ab6;">return</span> x

<span style="color: #531ab6;">def</span> <span style="color: #721045;">f</span><span style="color: #000000;">(</span>candidate<span style="color: #000000;">)</span>:
    <span style="color: #531ab6;">return</span> np.exp<span style="color: #000000;">(</span>-0.5 * candidate ** 2<span style="color: #000000;">)</span>

plt.hist<span style="color: #000000;">(</span>mcmc<span style="color: #dd22dd;">(</span>100000, f<span style="color: #dd22dd;">)</span>, bins=100, density=<span style="color: #0000b0;">True</span>, label=<span style="color: #3548cf;">"MCMC Histogram"</span><span style="color: #000000;">)</span>
plt.plot<span style="color: #000000;">(</span>np.arange<span style="color: #dd22dd;">(</span>-4,4,0.01<span style="color: #dd22dd;">)</span>, norm.pdf<span style="color: #dd22dd;">(</span>np.arange<span style="color: #008899;">(</span>-4,4,0.01<span style="color: #008899;">)</span>, 0, 1<span style="color: #dd22dd;">)</span>, label=<span style="color: #3548cf;">"True Gaussian Distribution"</span><span style="color: #000000;">)</span>
<span style="color: #005e8b;">_</span> = plt.legend<span style="color: #000000;">(</span>loc=<span style="color: #3548cf;">"upper right"</span><span style="color: #000000;">)</span>
</pre>
</div>


<div id="orgb185f87" class="figure">
<p><img src="./.ob-jupyter/41ece7c493e65f7272ba5de6612cdfe0169fb443.png" alt="41ece7c493e65f7272ba5de6612cdfe0169fb443.png" />
</p>
</div>
</div>
</div>
<div id="outline-container-org690bbe0" class="outline-4">
<h4 id="org690bbe0"><span class="section-number-4">1.5.5.</span> Proof</h4>
<div class="outline-text-4" id="text-1-5-5">
</div>
<ol class="org-ol">
<li><a id="orgf904f31"></a>Aperiodic and Irreducible<br />
<div class="outline-text-5" id="text-1-5-5-1">
<div class="THEOREM" id="orgcdff1a8">
<p>
An irreducible, aperiodic Markov chain has a unique stationary distribution if it exists.
</p>

</div>

<div class="PROOF" id="org3cf9079">
<p>
In the book, Theorem 4.3.3.
</p>

</div>
</div>
</li>
<li><a id="orgc3066de"></a>Detailed Balance<br />
<div class="outline-text-5" id="text-1-5-5-2">
<div class="DEFINITION" id="org02205fc">
<p>
Suppose we have a Markov Chain with:
</p>
<ul class="org-ul">
<li>Transition probabilities \( P_{ij} \)</li>
<li>Distribution of states \( \pi_i \)</li>
</ul>

<p>
Such that,
</p>

<p>
\( \pi_{i} P_{ij} = \pi_{j} P_{ji} \)
</p>

<p>
Then \( \pi_i \) satisfies detailed balance with respect to the Markov Chain.
</p>

</div>

<div class="THEOREM" id="orga90650a">
<p>
Suppose we have a Markov Chain with:
</p>
<ul class="org-ul">
<li>Transition probabilities \( P_{ij} \)</li>
<li>Distribution of states \( \pi_i \) that satisfies detailed balance.</li>
</ul>

<p>
Then \( \pi \) is a stationary distribution of the Markov Chain.
</p>

</div>

<div class="PROOF" id="orga9212de">
\begin{align*}
\forall j, \sum_{i} \pi_i P_{ij} = \sum_{i} \pi_j P_{ji} = \pi_j \sum_{i} P_{ji} = \pi_{j}
\end{align*}

</div>
</div>
</li>
<li><a id="orgf54fe93"></a>Proof<br />
<div class="outline-text-5" id="text-1-5-5-3">
<div class="PROOF" id="orgd0f4d8b">
<p>
Let
</p>
<ul class="org-ul">
<li>\( q(x^* \vert x) \) have nonzero density for every point in the target distribution</li>
<li>\( \alpha(x,x^*) = \min \left( 1, \frac{P(x^*) q(x \vert x^*)}{P(x) q(x^* \vert x)} \right) = \min \left( 1, \frac{f(x^*) q(x \vert x^*)}{f(x) q(x^* \vert x)} \right) \)</li>
<li>\( P_{x x^*} = P(X_n = x^* \vert X_{n-1} = x) = \begin{cases} q(x^* \vert x) \alpha(x,x^*) & x^* \neq x \\ q(x \vert x) + \sum_{x^* \neq x} q(x, x^*)(1 - \alpha(x,x^*)) & x^* = x \end{cases} \)</li>
</ul>

<p>
Note that \( \alpha(x,x^*) =  \) coordinatewise reciprocols of \( \alpha(x^*,x) \). so WLOG assume \( a(x^*,x) = 1, a(x,x^*) = \frac{P(x^*) q(x \vert x^*)}{P(x) q(x^* \vert x)} \)
Also note that detailed balence is statisfied when the two states are the same. Assume \( x^* \neq x \).
</p>

\begin{align}
&&f(x^*) q(x^* \vert x) &= f(x^*) q(x^* \vert x) \\
&\implies &\frac{f(x) q(x \vert x^*)}{f(x) q(x \vert x^*)}  f(x^*) q(x^* \vert x) &= f(x^*) q(x^* \vert x) \\
&\implies &f(x) q(x \vert x^*) \alpha(x,x^*) &= f(x^*) q(x^* \vert x) \alpha(x^*, x) \\
&\implies &p(x) q(x \vert x^*) \alpha(x,x^*) &= p(x^*) q(x^* \vert x) \alpha(x^*, x) \\
&\implies &p(x) P_{x,x^*} &= p(x^*) P_{x^*x}
\end{align}

<p>
Thus \( p(x) \) satisfies detailed balance and is stationary for the chain with transition probabilities \( P \) described above.
</p>

<p>
Uniqueness is determined by the choice of \( q \). Because \( q \) has nonzero density for every state, the chain can transition to any state from any other state, hence the chain is irreducible and aperiodic.
</p>

<p>
Thus, the Markov chain will converge to its unique stationary distribution \( \pi(i) \) as \( t \to \infty \) which is equal to \( p(i) \).
</p>

</div>
</div>
</li>
</ol>
</div>
<div id="outline-container-org713fba4" class="outline-4">
<h4 id="org713fba4"><span class="section-number-4">1.5.6.</span> Applications</h4>
<div class="outline-text-4" id="text-1-5-6">
<p>
Monte Carlo Markov Chain has many applications.
</p>
</div>
<ol class="org-ol">
<li><a id="org67c46cc"></a>Bayesian Inference<br />
<div class="outline-text-5" id="text-1-5-6-1">
<p>
Suppose we would like to know how likely parameters \( \theta \) are in a model to data \( X \).
</p>

<p>
That is, suppose we are given data from some experiment, and the histogram looks like a Normal distribution. 
</p>

<div class="org-src-container">
<pre class="src src-python3"><span style="color: #531ab6;">import</span> matplotlib.pyplot <span style="color: #531ab6;">as</span> plt
<span style="color: #531ab6;">import</span> numpy <span style="color: #531ab6;">as</span> np

<span style="color: #005e8b;">_</span> = plt.hist<span style="color: #000000;">(</span>np.random.normal<span style="color: #dd22dd;">(</span>3,4,50000<span style="color: #dd22dd;">)</span>, bins = 100, density=<span style="color: #0000b0;">True</span><span style="color: #000000;">)</span>
</pre>
</div>


<div id="org6a65b52" class="figure">
<p><img src="./.ob-jupyter/fce81b523ab0ccaf6d93dd848e8807250a351927.png" alt="fce81b523ab0ccaf6d93dd848e8807250a351927.png" />
</p>
</div>

<p>
Then we would like to model the data using the Normal distribution.
</p>

<p>
\[ \frac{1}{\sqrt{2 \pi \sigma^2}} e^{\frac{-1}{2} \left( \frac{x - \mu}{\sigma} \right)^2} \]
</p>


<p>
We would then like to ask, given the data, \( X \), what are the odds that the true mean and variance of the population is \( \mu = 0, \sigma^2 = 1 \). Symbolically,
</p>

<p>
\[ P(\mu = 0, \sigma^2 = 1 \vert X) = ? \]
</p>

<p>
We may compute this using Bayes' Theorem.
</p>

<p>
\[ P(\mu = 0, \sigma^2 = 1 \vert X) = \frac{P(X \vert \mu = 0, \sigma^2 = 1) P(\mu = 0, \sigma^2 = 1)}{P(X)} \]
</p>

<p>
The denominator is called the evidence, and is calculated using the law of total probability.
</p>

<p>
\[ P(X) = \int_{\theta \in \Theta} P(X \vert \theta) P(\theta) d \theta \]
</p>

<p>
This integral in general is very tough to compute. We may skip the process by noticing that
</p>

<p>
\[ P(\mu = 0, \sigma^2 = 1 \vert X) \propto P(X \vert \mu = 0, \sigma^2 = 1) P(\mu = 0, \sigma^2 = 1) \]
</p>

<p>
Hence we may calculate the probability density of \( P(\mu = 0, \sigma^2 = 1 \vert X) \) by running MCMC on \( f(\mu, \theta) = P(X \vert \mu, \sigma^2) P(\mu, \sigma^2) \).
</p>

<p>
This fundementally changed the course of statistics by allowing Bayesian Inference to be computationally tractible.
</p>

<p>
This approach allows for parameter estimation in models. My time with 'Ike Wai was about implementing an MCMC program in Matlab using multiple parallel chains to test convergence on some groundwater PDE's. <a href="https://github.com/Zaijab/DREAM">https://github.com/Zaijab/DREAM</a>
</p>

<p>
Here is a <a href="https://www.frontiersin.org/articles/10.3389/fams.2019.00055/full">paper</a> using MCMC for Bayesian Inference. Though there is no shortage of such papers.
</p>
</div>
</li>
<li><a id="org578082f"></a>Numerical Integration - How to calculate expectation and variance using Markov Chains<br />
<ol class="org-ol">
<li><a id="orgcd9a002"></a>Monte Carlo Integration<br />
<div class="outline-text-6" id="text-1-5-6-2-1">
<p>
One way to calculate an integral
</p>

<p>
\[ \int_{a}^{b} f(x) dx \]
</p>

<p>
Is to use samples randomly distributed over the interval \( [a,b] \).
</p>

<p>
That is, suppose we have a sequence of \( X_i \in [a,b] \) sampled iid uniformly.
</p>

<p>
Then,
</p>

\begin{align*}
\mathbb{E} \left[\frac{(b - a)}{n} \sum_{i = 0}^{n - 1} f(X_i) \right]
&= \frac{(b - a)}{n} \sum_{i = 0}^{n - 1} \mathbb{E} \left[ f(X_i) \right] \\
&= \frac{(b - a)}{n} \sum_{i = 0}^{n - 1} \int_{a}^{b} f(X_i) dP \\
&= \frac{(b - a)}{n} \sum_{i = 0}^{n - 1} \int_{a}^{b} f(x) \frac{1}{(b - a)} dx \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{a}^{b} f(x) dx \\
&= \int_{a}^{b} f(x) dx
\end{align*}

<p>
This works for numerical integration. Let us calculate \( \pi \) by numerically integrating over the semicircle.
</p>

<div class="org-src-container">
<pre class="src src-python3"><span style="color: #531ab6;">import</span> numpy <span style="color: #531ab6;">as</span> np
<span style="color: #531ab6;">def</span> <span style="color: #721045;">semicircle</span><span style="color: #000000;">(</span>x<span style="color: #000000;">)</span>:
    <span style="color: #531ab6;">return</span> np.sqrt<span style="color: #000000;">(</span>1 - x**2<span style="color: #000000;">)</span>
np.mean<span style="color: #000000;">(</span>np.vectorize<span style="color: #dd22dd;">(</span>semicircle<span style="color: #dd22dd;">)(</span>np.random.uniform<span style="color: #008899;">(</span>-1,1,100000<span style="color: #008899;">)</span><span style="color: #dd22dd;">)</span><span style="color: #000000;">)</span>*<span style="color: #000000;">(</span>4<span style="color: #000000;">)</span>
</pre>
</div>

<pre class="example">
3.1410804570775572
</pre>


<p>
Note the bounds of integration, we only proved this for a bounded domain of integration. What happens when the domain of integration is unbounded?
</p>
</div>
</li>
<li><a id="org6e36e58"></a>MCMC Integration<br />
<div class="outline-text-6" id="text-1-5-6-2-2">
<p>
Suppose we had an absolutely integrable function \( f \in L^1(\mathbb{R}) \).
</p>

<p>
We may integrate the function using the previous Monte Carlo method by approximating.
</p>

<p>
\[ \int_{-\infty}^{\infty} f(x) dx = \lim_{a \to \infty} \int_{-a}^{a} f(x) dx \]
</p>

<p>
However this does not work well computationally. The reason being, \( \lim_{x \to \infty} f(x) \to 0 \) 
</p>

<p>
This means that as the bounds of integration grows, the many new points will be very close to \( 0 \) and will not contribute much to the integral. So many points sampled by the computer will be for not much benefit. We would like a selection of points sampled "smartly". Rather than sample uniformly, we may sample according to the PDF of the \( X_i \). We can approximate the PDF using MCMC.
</p>

\begin{align*}
\mathbb{E} \left[\frac{1}{n} \sum_{i = 0}^{n - 1} \frac{f(X_i)}{p(X_i)} \right]
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \mathbb{E} \left[ \frac{f(X_i)}{p(X_i)} \right] \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{-\infty}^{\infty} \frac{f(X_i)}{p(X_i)} dP \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{-\infty}^{\infty} \frac{f(x)}{p(x)} p(x) dx \\
&= \frac{1}{n} \sum_{i = 0}^{n - 1} \int_{-\infty}^{\infty} f(x) dx \\
&= \int_{-\infty}^{\infty} f(x) dx
\end{align*}

<p>
Let us apply MCMC to numerically verify
</p>

<p>
\[ \int_{-\infty}^{\infty} \frac{1}{x^2 + 1} dx = \pi \]
</p>

<div class="org-src-container">
<pre class="src src-python3"><span style="color: #531ab6;">import</span> numpy <span style="color: #531ab6;">as</span> np
<span style="color: #531ab6;">import</span> random
<span style="color: #531ab6;">import</span> matplotlib.pyplot <span style="color: #531ab6;">as</span> plt
<span style="color: #531ab6;">from</span> scipy.stats <span style="color: #531ab6;">import</span> norm

<span style="color: #531ab6;">def</span> <span style="color: #721045;">f</span><span style="color: #000000;">(</span>candidate<span style="color: #000000;">)</span>:
    <span style="color: #531ab6;">return</span> 1 / <span style="color: #000000;">(</span>candidate**2 + 1<span style="color: #000000;">)</span>
<span style="color: #005e8b;">x</span> = mcmc<span style="color: #000000;">(</span>500000,f<span style="color: #000000;">)</span>
<span style="color: #005e8b;">counts</span>, <span style="color: #005e8b;">edges</span>, <span style="color: #005e8b;">bars</span> = plt.hist<span style="color: #000000;">(</span>x, bins=1000, density=<span style="color: #0000b0;">True</span>, label=<span style="color: #3548cf;">"MCMC Histogram"</span><span style="color: #000000;">)</span>
plt.close<span style="color: #000000;">()</span>

<span style="color: #531ab6;">def</span> <span style="color: #721045;">f_div_pdf</span><span style="color: #000000;">(</span>candidate<span style="color: #000000;">)</span>:
    <span style="color: #531ab6;">return</span> <span style="color: #000000;">(</span>1 / <span style="color: #dd22dd;">(</span>candidate**2 + 1<span style="color: #dd22dd;">)</span><span style="color: #000000;">)</span> / counts<span style="color: #000000;">[</span>np.where<span style="color: #dd22dd;">(</span>edges &gt;= candidate<span style="color: #dd22dd;">)[</span>0<span style="color: #dd22dd;">][</span>0<span style="color: #dd22dd;">]</span> - 1<span style="color: #000000;">]</span>

np.mean<span style="color: #000000;">(</span>np.vectorize<span style="color: #dd22dd;">(</span>f_div_pdf<span style="color: #dd22dd;">)(</span>np.array<span style="color: #008899;">(</span>x<span style="color: #008899;">)</span><span style="color: #dd22dd;">)</span><span style="color: #000000;">)</span>
</pre>
</div>

<pre class="example">
3.1352669999829894
</pre>


<p>
\newpage
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
<div id="outline-container-org987951e" class="outline-4">
<h4 id="org987951e"><span class="section-number-4">1.5.7.</span> References</h4>
<div class="outline-text-4" id="text-1-5-7">
<p>
Ross, S. M. (1996). Stochastic processes. India: Wiley.
</p>

<p>
Matsuura, S., Hanada, M. (2022). MCMC from Scratch: A Practical Introduction to Markov Chain Monte Carlo. Singapore: Springer Nature Singapore.
</p>

<p>
Mangla, C., Holden, S.B., Paulson, L.C. (2022). Bayesian Ranking for Strategy Scheduling in Automated Theorem Provers. In: Blanchette, J., Kovcs, L., Pattinson, D. (eds) Automated Reasoning. IJCAR 2022. Lecture Notes in Computer Science(), vol 13385. Springer, Cham. <a href="https://doi.org/10.1007/978-3-031-10769-6_33">https://doi.org/10.1007/978-3-031-10769-6_33</a>
</p>

<p>
SpartacanUsuals, director. YouTube, YouTube, 15 May 2018, <a href="https://www.youtube.com/watch?v=0MzH69hFdkE">https://www.youtube.com/watch?v=0MzH69hFdkE</a>. Accessed 30 Nov. 2022.
</p>

<p>
Valderrama-Bahamndez GI and Frhlich H (2019) MCMC Techniques for Parameter Estimation of ODE Based Models in Systems Biology. Front. Appl. Math. Stat. 5:55. doi: 10.3389/fams.2019.00055
</p>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
